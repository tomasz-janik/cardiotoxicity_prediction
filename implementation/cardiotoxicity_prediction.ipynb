{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e86ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "import numbers\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaabe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_PATH = Path.cwd().parent\n",
    "DATA_PATH = INITIAL_PATH / 'data'\n",
    "PREPROCESSED_DATA_PATH = DATA_PATH / 'preprocessed'\n",
    "RESULTS_DATA_PATH = INITIAL_PATH / 'results'\n",
    "SPLITTED_DATA_PATH = PREPROCESSED_DATA_PATH / 'splitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bf15b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_KLEKOTA_ROTH_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP.csv'\n",
    "PREPROCESSED_MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP.csv'\n",
    "PREPROCESSED_EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_ExtFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-ExtFP.csv'\n",
    "PREPROCESSED_MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP-ExtFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv'\n",
    "\n",
    "RESULTS_KLEKOTA_ROTH = RESULTS_DATA_PATH / 'KlekFP.csv'\n",
    "RESULTS_MACCS = RESULTS_DATA_PATH / 'MACCSFP.csv'\n",
    "RESULTS_EXT = RESULTS_DATA_PATH / 'ExtFP.csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS_DATA = RESULTS_DATA_PATH / 'KlekFP-MACCSFP.csv'\n",
    "RESULTS_KLEKOTA_ROTH__EXT_DATA = RESULTS_DATA_PATH / 'KlekFP-ExtFP.csv'\n",
    "RESULTS_MACCS__EXT_DATA = RESULTS_DATA_PATH / 'MACCSFP-ExtFP.csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA = RESULTS_DATA_PATH / 'KlekFP-MACCSFP-ExtFP.csv'\n",
    "\n",
    "RESULTS_DEEP_NEURAL_NETWORKS = RESULTS_DATA_PATH / 'deep_neural_networks' / 'results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e103cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_KLEKOTA_ROTH_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP[{}].csv'\n",
    "PREPROCESSED_MACCS_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_MACCSFP[{}].csv'\n",
    "PREPROCESSED_EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_ExtFP[{}].csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP-MACCSFP[{}].csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP-ExtFP[{}].csv'\n",
    "PREPROCESSED_MACCS__EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_MACCSFP-ExtFP[{}].csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv[{}]'\n",
    "\n",
    "RESULTS_KLEKOTA_ROTH_X = RESULTS_DATA_PATH / '{}/KlekFP[{}].csv'\n",
    "RESULTS_MACCS_X = RESULTS_DATA_PATH / '{}/MACCSFP[{}].csv'\n",
    "RESULTS_EXT_X = RESULTS_DATA_PATH / '{}/ExtFP[{}].csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS_DATA_X = RESULTS_DATA_PATH / '{}/KlekFP-MACCSFP[{}].csv'\n",
    "RESULTS_KLEKOTA_ROTH__EXT_DATA_X = RESULTS_DATA_PATH / '{}/KlekFP-ExtFP[{}].csv'\n",
    "RESULTS_MACCS__EXT_DATA_X = RESULTS_DATA_PATH / '{}/MACCSFP-ExtFP[{}].csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA_X = RESULTS_DATA_PATH / '{}/KlekFP-MACCSFP-ExtFP[{}].csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0b64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"Running GridSearchCV for {key} with params {self.params[key]} with number of features {len(X.columns)}\")\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4356ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparametersTuner():\n",
    "    \n",
    "    def apply(self, input_filepath, output_filepath):\n",
    "        df = pd.read_csv(input_filepath)\n",
    "    \n",
    "        X = df.drop(['IC50','toxic'], axis=1)\n",
    "        y = df['toxic']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "        \n",
    "        print(f'Running Hyperparameters Tunning for {input_filepath}')\n",
    "        helper = EstimatorSelectionHelper(self.__prepare_models(), self.__prepare_parameters())\n",
    "        helper.fit(X_train, y_train, scoring='f1', n_jobs=4, verbose=2)\n",
    "        \n",
    "        score_summary = helper.score_summary()\n",
    "        \n",
    "        score_summary.to_csv(output_filepath, index = False)\n",
    "        \n",
    "        return score_summary\n",
    "    \n",
    "    @staticmethod\n",
    "    def __prepare_models():\n",
    "        return {\n",
    "            'LogisticRegression': LogisticRegression(), \n",
    "            'RidgeClassifier': RidgeClassifier(), \n",
    "            'SGDClassifier': SGDClassifier(), \n",
    "            'SVC': SVC(),\n",
    "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "            'RandomForestClassifier': RandomForestClassifier(),\n",
    "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def __prepare_parameters():\n",
    "        return {\n",
    "            'LogisticRegression': {\n",
    "                'C': [0.01, 0.1, 1, 10],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'max_iter': list(range(100,500,100)),\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "            },\n",
    "            'RidgeClassifier': {\n",
    "                'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'SGDClassifier': {\n",
    "                'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                'max_iter': list(range(100,500,100)),\n",
    "                'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "            },\n",
    "            'SVC': {\n",
    "                'C': [0.01, 0.1, 1, 10],\n",
    "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "            },\n",
    "            'ExtraTreesClassifier': {\n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "            },\n",
    "            'RandomForestClassifier': { \n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "            },\n",
    "            'AdaBoostClassifier':  { \n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "            },\n",
    "            'GradientBoostingClassifier': { \n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "                'learning_rate': [0.4, 0.6, 0.8, 1.0] \n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5aea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameters Tunning for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_KlekFP.csv\n",
      "Running GridSearchCV for LogisticRegression with params {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'max_iter': [100, 200, 300, 400], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} with number of features 2100\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "data_to_process = [\n",
    "    (PREPROCESSED_KLEKOTA_ROTH_DATA, RESULTS_KLEKOTA_ROTH), \n",
    "    (PREPROCESSED_MACCS_DATA, RESULTS_MACCS), \n",
    "    (PREPROCESSED_EXT_DATA, RESULTS_EXT),\n",
    "    \n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA, RESULTS_KLEKOTA_ROTH__MACCS_DATA),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__EXT_DATA, RESULTS_KLEKOTA_ROTH__EXT_DATA),\n",
    "    (PREPROCESSED_MACCS__EXT_DATA, RESULTS_MACCS__EXT_DATA),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA, RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA)\n",
    "]\n",
    "\n",
    "hyperparameters_tuner = HyperparametersTuner()\n",
    "results = []\n",
    "\n",
    "for data in data_to_process:\n",
    "    result = hyperparameters_tuner.apply(data[0], data[1])\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae2e7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameters Tunning for C:\\Users\\SG0306249\\PycharmProjects\\cardiotoxicity_prediction\\data\\preprocessed\\splitted\\2000\\cardiotoxicity_hERG_KlekFP-MACCSFP[2000].csv\n",
      "Running GridSearchCV for LogisticRegression with params {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'max_iter': [100, 200, 300, 400], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} with number of features 2000\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.48588979        nan 0.48596103 0.69067866\n",
      " 0.69059572 0.69084248 0.69059572 0.69068058        nan        nan\n",
      " 0.48588979        nan 0.48596103 0.69067866 0.69059572 0.69084248\n",
      " 0.69059572 0.69068058        nan        nan 0.48588979        nan\n",
      " 0.48596103 0.69067866 0.69059572 0.69084248 0.69059572 0.69068058\n",
      "        nan        nan 0.48588979        nan 0.48596103 0.69067866\n",
      " 0.69059572 0.69084248 0.69059572 0.69068058        nan        nan\n",
      " 0.68189834        nan 0.68018731 0.72986849 0.73093232 0.72874299\n",
      " 0.72986849 0.72958696        nan        nan 0.68181628        nan\n",
      " 0.68018731 0.72986849 0.72986849 0.72874299 0.72986849 0.72941822\n",
      "        nan        nan 0.68197965        nan 0.68018731 0.72986849\n",
      " 0.72986849 0.72874299 0.72986849 0.72986849        nan        nan\n",
      " 0.68197965        nan 0.68018731 0.72986849 0.72986849 0.72874299\n",
      " 0.72986849 0.72986849        nan        nan 0.7400974         nan\n",
      " 0.73694238 0.74212604 0.74150469 0.74216288 0.74197455 0.74182498\n",
      "        nan        nan 0.74018643        nan 0.73841553 0.74212604\n",
      " 0.74146998 0.74216288 0.74173379 0.74221429        nan        nan\n",
      " 0.74004054        nan 0.73773126 0.74212604 0.74110479 0.74216288\n",
      " 0.7419742  0.74212613        nan        nan 0.74024318        nan\n",
      " 0.73864806 0.74212604 0.74221925 0.74216288 0.7419742  0.74173399\n",
      "        nan        nan 0.73332159        nan 0.73611607 0.73814515\n",
      " 0.72777312 0.73838467 0.73585888 0.73607931        nan        nan\n",
      " 0.73278566        nan 0.73585061 0.73814515 0.73488898 0.73838467\n",
      " 0.7358091  0.73540578        nan        nan 0.73332159        nan\n",
      " 0.73605284 0.73814515 0.73825992 0.73838467 0.73652995 0.73567034\n",
      "        nan        nan 0.73310507        nan 0.73520628 0.73814515\n",
      " 0.73796812 0.73838467 0.73727185 0.73559415]\n",
      "  warnings.warn(\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.48835237        nan 0.48835237 0.71492252\n",
      " 0.71496527 0.71722837 0.71492252 0.71487909        nan        nan\n",
      " 0.48835237        nan 0.48835237 0.71492252 0.71496527 0.71722837\n",
      " 0.71492252 0.71487909        nan        nan 0.48835237        nan\n",
      " 0.48835237 0.71492252 0.71496527 0.71722837 0.71492252 0.71487909\n",
      "        nan        nan 0.48835237        nan 0.48835237 0.71492252\n",
      " 0.71496527 0.71722837 0.71492252 0.71487909        nan        nan\n",
      " 0.70753157        nan 0.70491623 0.78044775 0.77968257 0.78028711\n",
      " 0.78044775 0.78030374        nan        nan 0.70748779        nan\n",
      " 0.70483689 0.78044775 0.78052006 0.78028711 0.78044775 0.78042165\n",
      "        nan        nan 0.70753157        nan 0.70483689 0.78044775\n",
      " 0.78052006 0.78028711 0.78044775 0.78044775        nan        nan\n",
      " 0.70748937        nan 0.70483689 0.78044775 0.78052006 0.78028711\n",
      " 0.78044775 0.78044775        nan        nan 0.81442129        nan\n",
      " 0.8092967  0.8277559  0.82654622 0.82823245 0.82786432 0.82447484\n",
      "        nan        nan 0.8143995         nan 0.81055432 0.8277559\n",
      " 0.82833943 0.82823245 0.82802211 0.82788452        nan        nan\n",
      " 0.81451735        nan 0.81241142 0.8277559  0.82847538 0.82823245\n",
      " 0.82790385 0.82827878        nan        nan 0.81437329        nan\n",
      " 0.81270212 0.8277559  0.8277345  0.82823245 0.82785437 0.82802211\n",
      "        nan        nan 0.8649404         nan 0.83559694 0.85831266\n",
      " 0.83872673 0.85856582 0.84637049 0.83641733        nan        nan\n",
      " 0.86495747        nan 0.84539879 0.85831266 0.85291857 0.85856582\n",
      " 0.85234453 0.84601234        nan        nan 0.86495747        nan\n",
      " 0.84956257 0.85831266 0.85766475 0.85856582 0.85531107 0.85049607\n",
      "        nan        nan 0.86490597        nan 0.85198302 0.85831266\n",
      " 0.85787293 0.85856582 0.85662011 0.85203993]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RidgeClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Running GridSearchCV for SGDClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'penalty': ['l1', 'l2', 'elasticnet'], 'max_iter': [100, 200, 300, 400], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']} with number of features 2000\n",
      "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n",
      "Running GridSearchCV for SVC with params {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} with number of features 2000\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Running GridSearchCV for ExtraTreesClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running GridSearchCV for RandomForestClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for AdaBoostClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'learning_rate': [0.4, 0.6, 0.8, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running Hyperparameters Tunning for C:\\Users\\SG0306249\\PycharmProjects\\cardiotoxicity_prediction\\data\\preprocessed\\splitted\\2000\\cardiotoxicity_hERG_KlekFP-ExtFP[2000].csv\n",
      "Running GridSearchCV for LogisticRegression with params {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'max_iter': [100, 200, 300, 400], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} with number of features 2000\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53314087        nan 0.54491542 0.70194256\n",
      " 0.70185711 0.7028758  0.70178708 0.70149743        nan        nan\n",
      " 0.53314087        nan 0.54491542 0.70194256 0.70194256 0.7028758\n",
      " 0.70178708 0.70137153        nan        nan 0.53314087        nan\n",
      " 0.54491542 0.70194256 0.70194256 0.7028758  0.70178708 0.70155256\n",
      "        nan        nan 0.53314087        nan 0.54491542 0.70194256\n",
      " 0.70194256 0.7028758  0.70178708 0.70178708        nan        nan\n",
      " 0.69978221        nan 0.70037012 0.7197768  0.71961657 0.71909587\n",
      " 0.71945968 0.71943806        nan        nan 0.69986457        nan\n",
      " 0.70102575 0.7197768  0.72028773 0.71909587 0.71958349 0.71945968\n",
      "        nan        nan 0.69978221        nan 0.70102494 0.7197768\n",
      " 0.71953905 0.71909587 0.71995061 0.71951145        nan        nan\n",
      " 0.69978221        nan 0.70102494 0.7197768  0.7197768  0.71909587\n",
      " 0.7196248  0.71934359        nan        nan 0.72295369        nan\n",
      " 0.72251015 0.72661828 0.72352337 0.72661564 0.72487656 0.72496281\n",
      "        nan        nan 0.72295369        nan 0.72442815 0.72661828\n",
      " 0.72696693 0.72661564 0.72572169 0.72524452        nan        nan\n",
      " 0.72310677        nan 0.72404806 0.72661828 0.72723082 0.72661564\n",
      " 0.72659327 0.72539284        nan        nan 0.72295369        nan\n",
      " 0.72469745 0.72661828 0.7261997  0.72661564 0.72652954 0.72563599\n",
      "        nan        nan 0.72140327        nan 0.72575101 0.72252365\n",
      " 0.7215641  0.7224354  0.72595363 0.72575346        nan        nan\n",
      " 0.72140327        nan 0.72613503 0.72252365 0.72287948 0.7224354\n",
      " 0.72514356 0.72602461        nan        nan 0.7210826         nan\n",
      " 0.72672955 0.72252365 0.72011168 0.7224354  0.72380255 0.72643164\n",
      "        nan        nan 0.721339          nan 0.72480505 0.72252365\n",
      " 0.71818903 0.7224354  0.72274148 0.72568888]\n",
      "  warnings.warn(\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.53650138        nan 0.54786373 0.75989831\n",
      " 0.75962716 0.76000935 0.76011326 0.75964827        nan        nan\n",
      " 0.53650138        nan 0.54786373 0.75989831 0.76007433 0.76000935\n",
      " 0.75982458 0.76006624        nan        nan 0.53650138        nan\n",
      " 0.54786373 0.75989831 0.76007433 0.76000935 0.75982458 0.75999608\n",
      "        nan        nan 0.53650138        nan 0.54786373 0.75989831\n",
      " 0.76007433 0.76000935 0.75982458 0.75999644        nan        nan\n",
      " 0.74802006        nan 0.74823575 0.80460802 0.80463455 0.80578716\n",
      " 0.80543965 0.80569934        nan        nan 0.74813689        nan\n",
      " 0.74764877 0.80460802 0.80478062 0.80578716 0.80507788 0.80541527\n",
      "        nan        nan 0.74791713        nan 0.74748544 0.80460802\n",
      " 0.80472515 0.80578716 0.80477167 0.80532061        nan        nan\n",
      " 0.74796156        nan 0.74748544 0.80460802 0.80467806 0.80578716\n",
      " 0.80467771 0.8049851         nan        nan 0.83065715        nan\n",
      " 0.81880523 0.8442552  0.82986847 0.84473784 0.83862502 0.83101112\n",
      "        nan        nan 0.8307267         nan 0.82521616 0.8442552\n",
      " 0.84379784 0.84473784 0.84283488 0.83849408        nan        nan\n",
      " 0.83065715        nan 0.82601564 0.8442552  0.8448405  0.84473784\n",
      " 0.8440568  0.84169577        nan        nan 0.8307267         nan\n",
      " 0.82751462 0.8442552  0.84458157 0.84473784 0.84448158 0.84278449\n",
      "        nan        nan 0.87924722        nan 0.83185472 0.87265191\n",
      " 0.83222015 0.87257977 0.84526654 0.83350935        nan        nan\n",
      " 0.87926244        nan 0.84315198 0.87265191 0.85356136 0.87257977\n",
      " 0.85409755 0.8447915         nan        nan 0.8793144         nan\n",
      " 0.84959486 0.87265191 0.86254037 0.87257977 0.85948118 0.85137231\n",
      "        nan        nan 0.87926244        nan 0.85369291 0.87265191\n",
      " 0.86865283 0.87257977 0.86239188 0.85426936]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RidgeClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Running GridSearchCV for SGDClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'penalty': ['l1', 'l2', 'elasticnet'], 'max_iter': [100, 200, 300, 400], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']} with number of features 2000\n",
      "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n",
      "Running GridSearchCV for SVC with params {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} with number of features 2000\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Running GridSearchCV for ExtraTreesClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running GridSearchCV for RandomForestClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for AdaBoostClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'learning_rate': [0.4, 0.6, 0.8, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "data_to_process = [\n",
    "    (PREPROCESSED_KLEKOTA_ROTH_DATA_X, RESULTS_KLEKOTA_ROTH_X), \n",
    "    (PREPROCESSED_MACCS_DATA_X, RESULTS_MACCS_X), \n",
    "    (PREPROCESSED_EXT_DATA_X, RESULTS_EXT_X),\n",
    "    \n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA_X, RESULTS_KLEKOTA_ROTH__MACCS_DATA_X),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__EXT_DATA_X, RESULTS_KLEKOTA_ROTH__EXT_DATA_X),\n",
    "    (PREPROCESSED_MACCS__EXT_DATA_X, RESULTS_MACCS__EXT_DATA_X),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA_X, RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA_X)\n",
    "]\n",
    "\n",
    "hyperparameters_tuner = HyperparametersTuner()\n",
    "results = []\n",
    "\n",
    "for x in range(500, 2500, 500):\n",
    "    for data in data_to_process:\n",
    "        input_path = Path(str(data[0]).format(x, x))\n",
    "        output_path = Path(str(data[1]).format(x, x))\n",
    "        try:\n",
    "            result = hyperparameters_tuner.apply(input_path, output_path)\n",
    "            results.append(result)\n",
    "        except:\n",
    "            print(f'Ignoring {input_path} because the file does not exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c65ca7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras.layers as layers\n",
    "\n",
    "class DeepNeuralNetworkTuner():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def apply(self, input_file):\n",
    "        print(f'Running Deep Neural Network Tuner for {input_file}')\n",
    "        df = pd.read_csv(input_file)\n",
    "        filename = str(input_file).split('\\\\')[-1]\n",
    "        data_type = filename.split('.')[0]\n",
    "        \n",
    "        X = df.drop(['IC50','toxic'], axis=1)\n",
    "        y = df['toxic']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "        \n",
    "        number_of_columns = len(X_train.columns)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test) \n",
    "        \n",
    "        models = {\n",
    "            \"Model_1\": keras.Sequential([\n",
    "                keras.layers.Dense(128, input_shape=(number_of_columns,), kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "                keras.layers.Dense(16, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "            ]),\n",
    "            \"Model_2\": keras.Sequential([\n",
    "                keras.layers.Dense(128, input_shape=(number_of_columns,), kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "                keras.layers.Dense(256, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "                keras.layers.Dense(256, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "                keras.layers.Dense(512, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "                keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "            ]),\n",
    "            \"Model_3\": keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(number_of_columns,)),\n",
    "                keras.layers.Dense(16, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "            ]),\n",
    "            \"Model_4\": keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(number_of_columns,)),\n",
    "                keras.layers.Dense(32, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                keras.layers.Dense(16, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "            ]),\n",
    "            \"Model_5\": keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(number_of_columns,)),\n",
    "                keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "                keras.layers.Dense(32, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                keras.layers.Dense(16, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "            ])\n",
    "        }\n",
    "            \n",
    "        for model_name, model in models.items():\n",
    "            model.compile(optimizer='adam',\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                           mode='max',\n",
    "                                                           patience=10,\n",
    "                                                           restore_best_weights=True)\n",
    "\n",
    "            print(f'Running {model_name}')\n",
    "            model.fit(X_train, y_train, \n",
    "                      epochs=300, \n",
    "                      batch_size=10,\n",
    "                      callbacks=[early_stopping],\n",
    "                      validation_split=0.2,\n",
    "                      shuffle=True)\n",
    "\n",
    "            test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "            print(f'Finished {model_name}, got results: test_loss={test_loss}, test_acc={test_acc}')\n",
    "            \n",
    "            self.results[f'{data_type}_{model_name}'] = {\n",
    "                'test_acc':test_acc,\n",
    "                'test_loss':test_loss    \n",
    "            }\n",
    "    \n",
    "    def summary(self, output_file):\n",
    "        sorted_results = {k: v for k, v in sorted(self.results.items(), key=lambda item: item[1]['test_acc'], reverse=True)}\n",
    "        df = pd.DataFrame(sorted_results)\n",
    "        df.to_csv(output_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f3122d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_KlekFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 6s 8ms/step - loss: 2.8486 - accuracy: 0.6483 - val_loss: 1.3574 - val_accuracy: 0.6833\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 6s 8ms/step - loss: 1.1894 - accuracy: 0.7056 - val_loss: 1.1088 - val_accuracy: 0.7045\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 1.0664 - accuracy: 0.7233 - val_loss: 1.0448 - val_accuracy: 0.7027\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0041 - accuracy: 0.7373 - val_loss: 1.0355 - val_accuracy: 0.7127\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 0.9889 - accuracy: 0.7442 - val_loss: 1.0434 - val_accuracy: 0.7192\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.9528 - accuracy: 0.7480 - val_loss: 0.9990 - val_accuracy: 0.7133\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 5s 7ms/step - loss: 0.9331 - accuracy: 0.7398 - val_loss: 0.9312 - val_accuracy: 0.7162\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 0.9093 - accuracy: 0.7495 - val_loss: 0.9951 - val_accuracy: 0.7297\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 4s 5ms/step - loss: 0.9321 - accuracy: 0.7517 - val_loss: 0.9890 - val_accuracy: 0.7356\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8909 - accuracy: 0.7518 - val_loss: 0.9241 - val_accuracy: 0.7327\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.8933 - accuracy: 0.7490 - val_loss: 0.9715 - val_accuracy: 0.7262\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 5s 7ms/step - loss: 0.8729 - accuracy: 0.7535 - val_loss: 0.9144 - val_accuracy: 0.7192\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 5s 7ms/step - loss: 0.8921 - accuracy: 0.7551 - val_loss: 0.9402 - val_accuracy: 0.7186\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 0.8715 - accuracy: 0.7524 - val_loss: 0.9368 - val_accuracy: 0.7109\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 0.8743 - accuracy: 0.7514 - val_loss: 0.9151 - val_accuracy: 0.7162\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 0.8775 - accuracy: 0.7558 - val_loss: 0.9055 - val_accuracy: 0.7262\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 5s 8ms/step - loss: 0.8562 - accuracy: 0.7510 - val_loss: 0.8975 - val_accuracy: 0.7268\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 6s 8ms/step - loss: 0.8736 - accuracy: 0.7526 - val_loss: 0.9549 - val_accuracy: 0.7215\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 6s 8ms/step - loss: 0.8628 - accuracy: 0.7526 - val_loss: 0.9039 - val_accuracy: 0.7297\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 1.0034 - accuracy: 0.7132\n",
      "Finished Model_1, got results: test_loss=1.0034217834472656, test_acc=0.7132111191749573\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 9s 13ms/step - loss: 5.1162 - accuracy: 0.5032 - val_loss: 1.0002 - val_accuracy: 0.5018\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0008 - accuracy: 0.5004 - val_loss: 1.0016 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0011 - accuracy: 0.4972 - val_loss: 1.0014 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0011 - accuracy: 0.5010 - val_loss: 1.0024 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 4ms/step - loss: 1.0012 - accuracy: 0.5025 - val_loss: 1.0000 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0012 - accuracy: 0.5025 - val_loss: 1.0013 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0012 - accuracy: 0.4975 - val_loss: 1.0014 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0012 - accuracy: 0.4907 - val_loss: 1.0013 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0012 - accuracy: 0.5025 - val_loss: 1.0006 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0011 - accuracy: 0.4952 - val_loss: 1.0013 - val_accuracy: 0.5018\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0012 - accuracy: 0.4931 - val_loss: 1.0011 - val_accuracy: 0.5018\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=0.9998300075531006, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7188 - accuracy: 0.6848 - val_loss: 0.6359 - val_accuracy: 0.7391\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 939us/step - loss: 0.4806 - accuracy: 0.7939 - val_loss: 0.6100 - val_accuracy: 0.7444\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 936us/step - loss: 0.4271 - accuracy: 0.8247 - val_loss: 0.5820 - val_accuracy: 0.7603\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 924us/step - loss: 0.4028 - accuracy: 0.8425 - val_loss: 0.6015 - val_accuracy: 0.7703\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 949us/step - loss: 0.3744 - accuracy: 0.8581 - val_loss: 0.6253 - val_accuracy: 0.7744\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 941us/step - loss: 0.3637 - accuracy: 0.8645 - val_loss: 0.6575 - val_accuracy: 0.7638\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 956us/step - loss: 0.3426 - accuracy: 0.8816 - val_loss: 0.6734 - val_accuracy: 0.7697\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 947us/step - loss: 0.3389 - accuracy: 0.8897 - val_loss: 0.6742 - val_accuracy: 0.7803\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 906us/step - loss: 0.3226 - accuracy: 0.8939 - val_loss: 0.7019 - val_accuracy: 0.7679\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 897us/step - loss: 0.3207 - accuracy: 0.8973 - val_loss: 0.7192 - val_accuracy: 0.7662\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 926us/step - loss: 0.3090 - accuracy: 0.9004 - val_loss: 0.7290 - val_accuracy: 0.7644\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 915us/step - loss: 0.3080 - accuracy: 0.9024 - val_loss: 0.7437 - val_accuracy: 0.7662\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 907us/step - loss: 0.2965 - accuracy: 0.9114 - val_loss: 0.7592 - val_accuracy: 0.7732\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 922us/step - loss: 0.3005 - accuracy: 0.9120 - val_loss: 0.7604 - val_accuracy: 0.7679\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 941us/step - loss: 0.2958 - accuracy: 0.9104 - val_loss: 0.7509 - val_accuracy: 0.7703\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2915 - accuracy: 0.9171 - val_loss: 0.8047 - val_accuracy: 0.7615\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 941us/step - loss: 0.2916 - accuracy: 0.9220 - val_loss: 0.7914 - val_accuracy: 0.7650\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 927us/step - loss: 0.2802 - accuracy: 0.9229 - val_loss: 0.7950 - val_accuracy: 0.7803\n",
      "67/67 [==============================] - 0s 844us/step - loss: 0.7091 - accuracy: 0.7583\n",
      "Finished Model_3, got results: test_loss=0.7091459631919861, test_acc=0.7583450675010681\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6491 - accuracy: 0.7028 - val_loss: 0.5787 - val_accuracy: 0.7562\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4981 - accuracy: 0.8014 - val_loss: 0.5984 - val_accuracy: 0.7573\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4408 - accuracy: 0.8340 - val_loss: 0.6170 - val_accuracy: 0.7714\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4078 - accuracy: 0.8579 - val_loss: 0.6436 - val_accuracy: 0.7597\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3898 - accuracy: 0.8700 - val_loss: 0.6606 - val_accuracy: 0.7667\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3698 - accuracy: 0.8807 - val_loss: 0.6958 - val_accuracy: 0.7591\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3592 - accuracy: 0.8916 - val_loss: 0.6874 - val_accuracy: 0.7656\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3512 - accuracy: 0.8994 - val_loss: 0.7072 - val_accuracy: 0.7761\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3498 - accuracy: 0.9019 - val_loss: 0.7568 - val_accuracy: 0.7679\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.9029 - val_loss: 0.7540 - val_accuracy: 0.7650\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3294 - accuracy: 0.9083 - val_loss: 0.7818 - val_accuracy: 0.7662\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3209 - accuracy: 0.9180 - val_loss: 0.7487 - val_accuracy: 0.7761\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3152 - accuracy: 0.9173 - val_loss: 0.8006 - val_accuracy: 0.7744\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3192 - accuracy: 0.9186 - val_loss: 0.7849 - val_accuracy: 0.7697\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3151 - accuracy: 0.9234 - val_loss: 0.7732 - val_accuracy: 0.7750\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3007 - accuracy: 0.9277 - val_loss: 0.7857 - val_accuracy: 0.7744\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3009 - accuracy: 0.9270 - val_loss: 0.7964 - val_accuracy: 0.7814\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3011 - accuracy: 0.9249 - val_loss: 0.8242 - val_accuracy: 0.7656\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3047 - accuracy: 0.9267 - val_loss: 0.8450 - val_accuracy: 0.7667\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2919 - accuracy: 0.9296 - val_loss: 0.8033 - val_accuracy: 0.7720\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2864 - accuracy: 0.9312 - val_loss: 0.8565 - val_accuracy: 0.7685\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2897 - accuracy: 0.9292 - val_loss: 0.8525 - val_accuracy: 0.7691\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2820 - accuracy: 0.9302 - val_loss: 0.9014 - val_accuracy: 0.7714\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2931 - accuracy: 0.9283 - val_loss: 0.8671 - val_accuracy: 0.7685\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2883 - accuracy: 0.9354 - val_loss: 0.8642 - val_accuracy: 0.7667\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2902 - accuracy: 0.9340 - val_loss: 0.8611 - val_accuracy: 0.7732\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2820 - accuracy: 0.9334 - val_loss: 0.8959 - val_accuracy: 0.7667\n",
      "67/67 [==============================] - 0s 978us/step - loss: 0.8552 - accuracy: 0.7551\n",
      "Finished Model_4, got results: test_loss=0.8552049994468689, test_acc=0.7550540566444397\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 2.0288 - accuracy: 0.6628 - val_loss: 1.3060 - val_accuracy: 0.6792\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.1221 - accuracy: 0.7064 - val_loss: 1.0712 - val_accuracy: 0.7098\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9960 - accuracy: 0.7282 - val_loss: 0.9662 - val_accuracy: 0.7327\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9269 - accuracy: 0.7389 - val_loss: 0.9302 - val_accuracy: 0.7162\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8758 - accuracy: 0.7442 - val_loss: 0.8701 - val_accuracy: 0.7268\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8514 - accuracy: 0.7527 - val_loss: 0.8919 - val_accuracy: 0.7209\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8590 - accuracy: 0.7492 - val_loss: 0.8539 - val_accuracy: 0.7485\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8221 - accuracy: 0.7527 - val_loss: 0.8633 - val_accuracy: 0.7321\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8181 - accuracy: 0.7634 - val_loss: 0.8695 - val_accuracy: 0.7356\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8183 - accuracy: 0.7549 - val_loss: 0.8641 - val_accuracy: 0.7497\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8239 - accuracy: 0.7695 - val_loss: 0.8521 - val_accuracy: 0.7509\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8043 - accuracy: 0.7621 - val_loss: 0.8377 - val_accuracy: 0.7380\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8075 - accuracy: 0.7634 - val_loss: 0.8677 - val_accuracy: 0.7368\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8023 - accuracy: 0.7677 - val_loss: 0.8159 - val_accuracy: 0.7432\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7946 - accuracy: 0.7699 - val_loss: 0.8402 - val_accuracy: 0.7450\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8003 - accuracy: 0.7706 - val_loss: 0.8570 - val_accuracy: 0.7415\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8013 - accuracy: 0.7659 - val_loss: 0.8243 - val_accuracy: 0.7550\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8029 - accuracy: 0.7689 - val_loss: 0.9470 - val_accuracy: 0.7333\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8205 - accuracy: 0.7683 - val_loss: 0.8352 - val_accuracy: 0.7421\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7905 - accuracy: 0.7690 - val_loss: 0.8598 - val_accuracy: 0.7362\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7962 - accuracy: 0.7702 - val_loss: 0.8352 - val_accuracy: 0.7485\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7953 - accuracy: 0.7695 - val_loss: 0.8439 - val_accuracy: 0.7562\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7894 - accuracy: 0.7742 - val_loss: 0.8220 - val_accuracy: 0.7374\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7865 - accuracy: 0.7714 - val_loss: 0.8371 - val_accuracy: 0.7291\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7866 - accuracy: 0.7768 - val_loss: 0.8460 - val_accuracy: 0.7468\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7880 - accuracy: 0.7731 - val_loss: 0.8265 - val_accuracy: 0.7421\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7895 - accuracy: 0.7745 - val_loss: 0.8378 - val_accuracy: 0.7468\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7752 - accuracy: 0.7773 - val_loss: 0.8461 - val_accuracy: 0.7309\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7869 - accuracy: 0.7780 - val_loss: 0.8399 - val_accuracy: 0.7356\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7831 - accuracy: 0.7724 - val_loss: 0.8300 - val_accuracy: 0.7491\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7823 - accuracy: 0.7739 - val_loss: 0.8530 - val_accuracy: 0.7338\n",
      "Epoch 32/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7879 - accuracy: 0.7748 - val_loss: 0.8413 - val_accuracy: 0.7139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 1ms/step - loss: 0.8652 - accuracy: 0.7330\n",
      "Finished Model_5, got results: test_loss=0.8651915788650513, test_acc=0.7329572439193726\n",
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_MACCSFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 1.8269 - accuracy: 0.6502 - val_loss: 0.7611 - val_accuracy: 0.6798\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 921us/step - loss: 0.7289 - accuracy: 0.6815 - val_loss: 0.6955 - val_accuracy: 0.6880\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 936us/step - loss: 0.6816 - accuracy: 0.7014 - val_loss: 0.6779 - val_accuracy: 0.6992\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 917us/step - loss: 0.6629 - accuracy: 0.7004 - val_loss: 0.6600 - val_accuracy: 0.7115\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 898us/step - loss: 0.6502 - accuracy: 0.7114 - val_loss: 0.6563 - val_accuracy: 0.7051\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 884us/step - loss: 0.6417 - accuracy: 0.7135 - val_loss: 0.6543 - val_accuracy: 0.7098\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 944us/step - loss: 0.6370 - accuracy: 0.7227 - val_loss: 0.6587 - val_accuracy: 0.7109\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 977us/step - loss: 0.6307 - accuracy: 0.7226 - val_loss: 0.6559 - val_accuracy: 0.7145\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 963us/step - loss: 0.6316 - accuracy: 0.7208 - val_loss: 0.6441 - val_accuracy: 0.7162\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 899us/step - loss: 0.6261 - accuracy: 0.7238 - val_loss: 0.6495 - val_accuracy: 0.7092\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 886us/step - loss: 0.6235 - accuracy: 0.7272 - val_loss: 0.6423 - val_accuracy: 0.7156\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 890us/step - loss: 0.6239 - accuracy: 0.7273 - val_loss: 0.6496 - val_accuracy: 0.7192\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6219 - accuracy: 0.7274 - val_loss: 0.6461 - val_accuracy: 0.7127\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 899us/step - loss: 0.6182 - accuracy: 0.7307 - val_loss: 0.6431 - val_accuracy: 0.7068\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 857us/step - loss: 0.6192 - accuracy: 0.7276 - val_loss: 0.6357 - val_accuracy: 0.7385\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 946us/step - loss: 0.6184 - accuracy: 0.7301 - val_loss: 0.6465 - val_accuracy: 0.7244\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.7336 - val_loss: 0.6405 - val_accuracy: 0.7291\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6170 - accuracy: 0.7274 - val_loss: 0.6383 - val_accuracy: 0.7197\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 986us/step - loss: 0.6160 - accuracy: 0.7341 - val_loss: 0.6439 - val_accuracy: 0.7033\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 879us/step - loss: 0.6150 - accuracy: 0.7319 - val_loss: 0.6409 - val_accuracy: 0.7315\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 956us/step - loss: 0.6182 - accuracy: 0.7307 - val_loss: 0.6400 - val_accuracy: 0.7203\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 934us/step - loss: 0.6129 - accuracy: 0.7376 - val_loss: 0.6386 - val_accuracy: 0.7268\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 823us/step - loss: 0.6161 - accuracy: 0.7301 - val_loss: 0.6578 - val_accuracy: 0.7109\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 897us/step - loss: 0.6148 - accuracy: 0.7329 - val_loss: 0.6327 - val_accuracy: 0.7256\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 811us/step - loss: 0.6161 - accuracy: 0.7335 - val_loss: 0.6350 - val_accuracy: 0.7274\n",
      "67/67 [==============================] - 0s 533us/step - loss: 0.6427 - accuracy: 0.7156\n",
      "Finished Model_1, got results: test_loss=0.6427338719367981, test_acc=0.7155618071556091\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 4.4867 - accuracy: 0.5118 - val_loss: 0.8457 - val_accuracy: 0.5018\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8463 - accuracy: 0.4952 - val_loss: 0.8470 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8463 - accuracy: 0.4940 - val_loss: 0.8465 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.5025 - val_loss: 0.8465 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.4869 - val_loss: 0.8459 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8464 - accuracy: 0.5025 - val_loss: 0.8462 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.5004 - val_loss: 0.8460 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.4999 - val_loss: 0.8469 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.4999 - val_loss: 0.8462 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.5025 - val_loss: 0.8460 - val_accuracy: 0.5018\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.5004 - val_loss: 0.8461 - val_accuracy: 0.5018\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.8453 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=0.8453322649002075, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 724us/step - loss: 0.6574 - accuracy: 0.6415 - val_loss: 0.6099 - val_accuracy: 0.6915\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 0s 712us/step - loss: 0.5785 - accuracy: 0.7128 - val_loss: 0.5860 - val_accuracy: 0.7098\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 0s 636us/step - loss: 0.5503 - accuracy: 0.7333 - val_loss: 0.5762 - val_accuracy: 0.7280\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 0s 632us/step - loss: 0.5312 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7362\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 0s 677us/step - loss: 0.5163 - accuracy: 0.7608 - val_loss: 0.5634 - val_accuracy: 0.7280\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 0s 632us/step - loss: 0.5062 - accuracy: 0.7624 - val_loss: 0.5650 - val_accuracy: 0.7427\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 0s 705us/step - loss: 0.4962 - accuracy: 0.7680 - val_loss: 0.5604 - val_accuracy: 0.7374\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 0s 627us/step - loss: 0.4873 - accuracy: 0.7759 - val_loss: 0.5649 - val_accuracy: 0.7438\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 0s 632us/step - loss: 0.4794 - accuracy: 0.7805 - val_loss: 0.5572 - val_accuracy: 0.7474\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 0s 622us/step - loss: 0.4728 - accuracy: 0.7831 - val_loss: 0.5680 - val_accuracy: 0.7427\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 0s 665us/step - loss: 0.4664 - accuracy: 0.7849 - val_loss: 0.5595 - val_accuracy: 0.7462\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 0s 655us/step - loss: 0.4610 - accuracy: 0.7911 - val_loss: 0.5747 - val_accuracy: 0.7456\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 0s 612us/step - loss: 0.4538 - accuracy: 0.7997 - val_loss: 0.5661 - val_accuracy: 0.7491\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 0s 603us/step - loss: 0.4475 - accuracy: 0.8005 - val_loss: 0.5835 - val_accuracy: 0.7409\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 0s 618us/step - loss: 0.4432 - accuracy: 0.8078 - val_loss: 0.5711 - val_accuracy: 0.7515\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 0s 639us/step - loss: 0.4399 - accuracy: 0.8088 - val_loss: 0.5732 - val_accuracy: 0.7479\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 0s 628us/step - loss: 0.4360 - accuracy: 0.8112 - val_loss: 0.5769 - val_accuracy: 0.7450\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 0s 615us/step - loss: 0.4340 - accuracy: 0.8140 - val_loss: 0.5688 - val_accuracy: 0.7509\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 0s 633us/step - loss: 0.4288 - accuracy: 0.8187 - val_loss: 0.5748 - val_accuracy: 0.7474\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 0s 614us/step - loss: 0.4265 - accuracy: 0.8169 - val_loss: 0.5862 - val_accuracy: 0.7397\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 0s 625us/step - loss: 0.4278 - accuracy: 0.8197 - val_loss: 0.5875 - val_accuracy: 0.7444\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 0s 617us/step - loss: 0.4217 - accuracy: 0.8210 - val_loss: 0.5833 - val_accuracy: 0.7427\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 0s 676us/step - loss: 0.4174 - accuracy: 0.8306 - val_loss: 0.5921 - val_accuracy: 0.7450\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 0s 620us/step - loss: 0.4174 - accuracy: 0.8268 - val_loss: 0.5961 - val_accuracy: 0.7432\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 0s 632us/step - loss: 0.4151 - accuracy: 0.8301 - val_loss: 0.5977 - val_accuracy: 0.7450\n",
      "67/67 [==============================] - 0s 453us/step - loss: 0.5523 - accuracy: 0.7494\n",
      "Finished Model_3, got results: test_loss=0.5523473620414734, test_acc=0.7494122982025146\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 794us/step - loss: 0.6897 - accuracy: 0.6541 - val_loss: 0.6371 - val_accuracy: 0.6939\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 0s 669us/step - loss: 0.6002 - accuracy: 0.7214 - val_loss: 0.6102 - val_accuracy: 0.7197\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 0s 669us/step - loss: 0.5612 - accuracy: 0.7520 - val_loss: 0.5910 - val_accuracy: 0.7391\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 0s 677us/step - loss: 0.5346 - accuracy: 0.7676 - val_loss: 0.5839 - val_accuracy: 0.7521\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 0s 676us/step - loss: 0.5099 - accuracy: 0.7846 - val_loss: 0.5741 - val_accuracy: 0.7544\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 0s 677us/step - loss: 0.4936 - accuracy: 0.7936 - val_loss: 0.5858 - val_accuracy: 0.7573\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 0s 713us/step - loss: 0.4782 - accuracy: 0.8046 - val_loss: 0.5857 - val_accuracy: 0.7526\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 0s 666us/step - loss: 0.4653 - accuracy: 0.8166 - val_loss: 0.5825 - val_accuracy: 0.7673\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 0s 662us/step - loss: 0.4513 - accuracy: 0.8227 - val_loss: 0.5845 - val_accuracy: 0.7538\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 0s 717us/step - loss: 0.4418 - accuracy: 0.8329 - val_loss: 0.6103 - val_accuracy: 0.7568\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 0s 677us/step - loss: 0.4309 - accuracy: 0.8368 - val_loss: 0.5946 - val_accuracy: 0.7556\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 0s 676us/step - loss: 0.4229 - accuracy: 0.8444 - val_loss: 0.6125 - val_accuracy: 0.7532\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 0s 680us/step - loss: 0.4154 - accuracy: 0.8479 - val_loss: 0.6332 - val_accuracy: 0.7544\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 0s 673us/step - loss: 0.4077 - accuracy: 0.8535 - val_loss: 0.6141 - val_accuracy: 0.7556\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 0s 662us/step - loss: 0.3984 - accuracy: 0.8584 - val_loss: 0.6350 - val_accuracy: 0.7609\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 746us/step - loss: 0.3913 - accuracy: 0.8625 - val_loss: 0.6216 - val_accuracy: 0.7609\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.3875 - accuracy: 0.8651 - val_loss: 0.6652 - val_accuracy: 0.7526\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 0s 676us/step - loss: 0.3808 - accuracy: 0.8682 - val_loss: 0.6520 - val_accuracy: 0.7444\n",
      "67/67 [==============================] - 0s 460us/step - loss: 0.5757 - accuracy: 0.7616\n",
      "Finished Model_4, got results: test_loss=0.5757197737693787, test_acc=0.7616360783576965\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 838us/step - loss: 1.4444 - accuracy: 0.6446 - val_loss: 0.7758 - val_accuracy: 0.6769\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 753us/step - loss: 0.7233 - accuracy: 0.6869 - val_loss: 0.7025 - val_accuracy: 0.6921\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 753us/step - loss: 0.6750 - accuracy: 0.7011 - val_loss: 0.6793 - val_accuracy: 0.6821\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.6528 - accuracy: 0.7038 - val_loss: 0.6568 - val_accuracy: 0.7098\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.6424 - accuracy: 0.7107 - val_loss: 0.6486 - val_accuracy: 0.7062\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 0s 721us/step - loss: 0.6363 - accuracy: 0.7204 - val_loss: 0.6438 - val_accuracy: 0.7221\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.6314 - accuracy: 0.7180 - val_loss: 0.6437 - val_accuracy: 0.7221\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 0s 721us/step - loss: 0.6291 - accuracy: 0.7239 - val_loss: 0.6442 - val_accuracy: 0.7156\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 735us/step - loss: 0.6279 - accuracy: 0.7264 - val_loss: 0.6506 - val_accuracy: 0.6992\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 0s 721us/step - loss: 0.6231 - accuracy: 0.7223 - val_loss: 0.6530 - val_accuracy: 0.7203\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 0s 721us/step - loss: 0.6213 - accuracy: 0.7344 - val_loss: 0.6413 - val_accuracy: 0.7197\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.6218 - accuracy: 0.7305 - val_loss: 0.6395 - val_accuracy: 0.7180\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 795us/step - loss: 0.6177 - accuracy: 0.7339 - val_loss: 0.6420 - val_accuracy: 0.7168\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 0s 721us/step - loss: 0.6173 - accuracy: 0.7324 - val_loss: 0.6420 - val_accuracy: 0.7209\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.6156 - accuracy: 0.7332 - val_loss: 0.6541 - val_accuracy: 0.7056\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 735us/step - loss: 0.6156 - accuracy: 0.7304 - val_loss: 0.6499 - val_accuracy: 0.7115\n",
      "67/67 [==============================] - 0s 526us/step - loss: 0.6469 - accuracy: 0.7132\n",
      "Finished Model_5, got results: test_loss=0.6469058990478516, test_acc=0.7132111191749573\n",
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_ExtFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 3.2810 - accuracy: 0.6435 - val_loss: 1.1617 - val_accuracy: 0.6504\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 1.0346 - accuracy: 0.6674 - val_loss: 0.9597 - val_accuracy: 0.6675\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.9174 - accuracy: 0.6862 - val_loss: 0.8608 - val_accuracy: 0.6821\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8627 - accuracy: 0.7038 - val_loss: 0.8683 - val_accuracy: 0.6986\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8246 - accuracy: 0.7056 - val_loss: 0.8510 - val_accuracy: 0.6816\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8218 - accuracy: 0.7079 - val_loss: 0.8372 - val_accuracy: 0.6974\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8262 - accuracy: 0.7092 - val_loss: 0.8004 - val_accuracy: 0.7039\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7925 - accuracy: 0.7133 - val_loss: 0.8518 - val_accuracy: 0.6874\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7846 - accuracy: 0.7204 - val_loss: 0.8127 - val_accuracy: 0.6974\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7852 - accuracy: 0.7273 - val_loss: 0.8019 - val_accuracy: 0.6933\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7770 - accuracy: 0.7208 - val_loss: 0.8030 - val_accuracy: 0.7039\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7595 - accuracy: 0.7258 - val_loss: 0.7914 - val_accuracy: 0.6998\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7645 - accuracy: 0.7247 - val_loss: 0.8068 - val_accuracy: 0.7062\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.72 - 1s 1ms/step - loss: 0.7665 - accuracy: 0.7294 - val_loss: 0.7826 - val_accuracy: 0.7021\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7493 - accuracy: 0.7274 - val_loss: 0.8118 - val_accuracy: 0.6998\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7665 - accuracy: 0.7261 - val_loss: 0.7970 - val_accuracy: 0.7127\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7459 - accuracy: 0.7289 - val_loss: 0.7970 - val_accuracy: 0.6980\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7484 - accuracy: 0.7297 - val_loss: 0.8077 - val_accuracy: 0.7086\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7479 - accuracy: 0.7323 - val_loss: 0.7738 - val_accuracy: 0.7056\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7327 - accuracy: 0.7313 - val_loss: 0.7534 - val_accuracy: 0.7203\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7295 - accuracy: 0.7310 - val_loss: 0.7624 - val_accuracy: 0.7027\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7341 - accuracy: 0.7291 - val_loss: 0.7559 - val_accuracy: 0.7092\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7273 - accuracy: 0.7417 - val_loss: 0.7902 - val_accuracy: 0.6927\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.7374 - val_loss: 0.7755 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7232 - accuracy: 0.7368 - val_loss: 0.7720 - val_accuracy: 0.7009\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7342 - accuracy: 0.7289 - val_loss: 0.7739 - val_accuracy: 0.6933\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7298 - accuracy: 0.7330 - val_loss: 0.7754 - val_accuracy: 0.6957\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7238 - accuracy: 0.7348 - val_loss: 0.7652 - val_accuracy: 0.6992\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7265 - accuracy: 0.7332 - val_loss: 0.7671 - val_accuracy: 0.7015\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7262 - accuracy: 0.7363 - val_loss: 0.7627 - val_accuracy: 0.7109\n",
      "67/67 [==============================] - 0s 691us/step - loss: 0.7867 - accuracy: 0.6902\n",
      "Finished Model_1, got results: test_loss=0.786700963973999, test_acc=0.6901739835739136\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 5.0472 - accuracy: 0.5066 - val_loss: 0.9144 - val_accuracy: 0.5018\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9147 - accuracy: 0.5025 - val_loss: 0.9150 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9150 - accuracy: 0.4996 - val_loss: 0.9146 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9151 - accuracy: 0.4975 - val_loss: 0.9156 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9151 - accuracy: 0.4884 - val_loss: 0.9149 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9151 - accuracy: 0.5025 - val_loss: 0.9157 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9151 - accuracy: 0.4978 - val_loss: 0.9149 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9151 - accuracy: 0.5025 - val_loss: 0.9151 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9151 - accuracy: 0.4952 - val_loss: 0.9150 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9151 - accuracy: 0.5025 - val_loss: 0.9155 - val_accuracy: 0.5018\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9151 - accuracy: 0.4928 - val_loss: 0.9152 - val_accuracy: 0.5018\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=0.9139272570610046, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 823us/step - loss: 0.6632 - accuracy: 0.6844 - val_loss: 0.5652 - val_accuracy: 0.7338\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 0s 721us/step - loss: 0.5070 - accuracy: 0.7777 - val_loss: 0.5658 - val_accuracy: 0.7274\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 0s 735us/step - loss: 0.4560 - accuracy: 0.8043 - val_loss: 0.5647 - val_accuracy: 0.7427\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 0s 707us/step - loss: 0.4278 - accuracy: 0.8262 - val_loss: 0.5698 - val_accuracy: 0.7544\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 0s 706us/step - loss: 0.4019 - accuracy: 0.8450 - val_loss: 0.6009 - val_accuracy: 0.7485\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 0s 706us/step - loss: 0.3863 - accuracy: 0.8570 - val_loss: 0.5763 - val_accuracy: 0.7656\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 0s 691us/step - loss: 0.3664 - accuracy: 0.8667 - val_loss: 0.6068 - val_accuracy: 0.7656\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.3548 - accuracy: 0.8691 - val_loss: 0.6195 - val_accuracy: 0.7597\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 0s 713us/step - loss: 0.3436 - accuracy: 0.8823 - val_loss: 0.6459 - val_accuracy: 0.7491\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 0s 699us/step - loss: 0.3339 - accuracy: 0.8863 - val_loss: 0.6785 - val_accuracy: 0.7462\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 0s 706us/step - loss: 0.3251 - accuracy: 0.8932 - val_loss: 0.6725 - val_accuracy: 0.7503\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 0s 706us/step - loss: 0.3236 - accuracy: 0.8967 - val_loss: 0.6616 - val_accuracy: 0.7538\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 0s 706us/step - loss: 0.3143 - accuracy: 0.8985 - val_loss: 0.6683 - val_accuracy: 0.7656\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 0s 720us/step - loss: 0.3123 - accuracy: 0.9026 - val_loss: 0.7223 - val_accuracy: 0.7609\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 0s 703us/step - loss: 0.3085 - accuracy: 0.9063 - val_loss: 0.6950 - val_accuracy: 0.7644\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 0s 706us/step - loss: 0.3028 - accuracy: 0.9080 - val_loss: 0.7265 - val_accuracy: 0.7562\n",
      "67/67 [==============================] - 0s 498us/step - loss: 0.6098 - accuracy: 0.7522\n",
      "Finished Model_3, got results: test_loss=0.6097800135612488, test_acc=0.7522332072257996\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 912us/step - loss: 0.6720 - accuracy: 0.6867 - val_loss: 0.6200 - val_accuracy: 0.7174\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 809us/step - loss: 0.5488 - accuracy: 0.7749 - val_loss: 0.6003 - val_accuracy: 0.7450\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 809us/step - loss: 0.4900 - accuracy: 0.8180 - val_loss: 0.6340 - val_accuracy: 0.7450\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 809us/step - loss: 0.4650 - accuracy: 0.8341 - val_loss: 0.6177 - val_accuracy: 0.7603\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 794us/step - loss: 0.4360 - accuracy: 0.8510 - val_loss: 0.6411 - val_accuracy: 0.7479\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 779us/step - loss: 0.4210 - accuracy: 0.8589 - val_loss: 0.6559 - val_accuracy: 0.7591\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 779us/step - loss: 0.4052 - accuracy: 0.8704 - val_loss: 0.6854 - val_accuracy: 0.7597\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 809us/step - loss: 0.3924 - accuracy: 0.8788 - val_loss: 0.6973 - val_accuracy: 0.7562\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 794us/step - loss: 0.3874 - accuracy: 0.8808 - val_loss: 0.7104 - val_accuracy: 0.7579\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 839us/step - loss: 0.3793 - accuracy: 0.8879 - val_loss: 0.6934 - val_accuracy: 0.7591\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 794us/step - loss: 0.3676 - accuracy: 0.8922 - val_loss: 0.7282 - val_accuracy: 0.7562\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 825us/step - loss: 0.3679 - accuracy: 0.8941 - val_loss: 0.7208 - val_accuracy: 0.7591\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 881us/step - loss: 0.3629 - accuracy: 0.8948 - val_loss: 0.7497 - val_accuracy: 0.7579\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 808us/step - loss: 0.3583 - accuracy: 0.8952 - val_loss: 0.7500 - val_accuracy: 0.7609\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 809us/step - loss: 0.3550 - accuracy: 0.9026 - val_loss: 0.7637 - val_accuracy: 0.7597\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 863us/step - loss: 0.3527 - accuracy: 0.9046 - val_loss: 0.7723 - val_accuracy: 0.7562\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 884us/step - loss: 0.3579 - accuracy: 0.8986 - val_loss: 0.7494 - val_accuracy: 0.7532\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 807us/step - loss: 0.3417 - accuracy: 0.9093 - val_loss: 0.7980 - val_accuracy: 0.7485\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 792us/step - loss: 0.3499 - accuracy: 0.9085 - val_loss: 0.7687 - val_accuracy: 0.7644\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 787us/step - loss: 0.3398 - accuracy: 0.9102 - val_loss: 0.7875 - val_accuracy: 0.7620\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 868us/step - loss: 0.3468 - accuracy: 0.9082 - val_loss: 0.8035 - val_accuracy: 0.7656\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 880us/step - loss: 0.3387 - accuracy: 0.9127 - val_loss: 0.7806 - val_accuracy: 0.7568\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 832us/step - loss: 0.3428 - accuracy: 0.9129 - val_loss: 0.7950 - val_accuracy: 0.7468\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 842us/step - loss: 0.3277 - accuracy: 0.9185 - val_loss: 0.8235 - val_accuracy: 0.7585\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 838us/step - loss: 0.3306 - accuracy: 0.9174 - val_loss: 0.8065 - val_accuracy: 0.7597\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 838us/step - loss: 0.3358 - accuracy: 0.9135 - val_loss: 0.8170 - val_accuracy: 0.7603\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 849us/step - loss: 0.3277 - accuracy: 0.9180 - val_loss: 0.7861 - val_accuracy: 0.7620\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 832us/step - loss: 0.3260 - accuracy: 0.9176 - val_loss: 0.8073 - val_accuracy: 0.7509\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 1s 828us/step - loss: 0.3213 - accuracy: 0.9139 - val_loss: 0.8253 - val_accuracy: 0.7656\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 1s 887us/step - loss: 0.3342 - accuracy: 0.9161 - val_loss: 0.8085 - val_accuracy: 0.7673\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 1s 846us/step - loss: 0.3173 - accuracy: 0.9220 - val_loss: 0.8421 - val_accuracy: 0.7568\n",
      "Epoch 32/300\n",
      "681/681 [==============================] - 1s 856us/step - loss: 0.3188 - accuracy: 0.9239 - val_loss: 0.8357 - val_accuracy: 0.7497\n",
      "Epoch 33/300\n",
      "681/681 [==============================] - 1s 840us/step - loss: 0.3243 - accuracy: 0.9182 - val_loss: 0.7795 - val_accuracy: 0.7650\n",
      "Epoch 34/300\n",
      "681/681 [==============================] - 1s 838us/step - loss: 0.3179 - accuracy: 0.9249 - val_loss: 0.8340 - val_accuracy: 0.7609\n",
      "Epoch 35/300\n",
      "681/681 [==============================] - 1s 838us/step - loss: 0.3139 - accuracy: 0.9218 - val_loss: 0.8487 - val_accuracy: 0.7509\n",
      "Epoch 36/300\n",
      "681/681 [==============================] - 1s 838us/step - loss: 0.3160 - accuracy: 0.9186 - val_loss: 0.8380 - val_accuracy: 0.7579\n",
      "Epoch 37/300\n",
      "681/681 [==============================] - 1s 847us/step - loss: 0.3203 - accuracy: 0.9208 - val_loss: 0.8096 - val_accuracy: 0.7597\n",
      "Epoch 38/300\n",
      "681/681 [==============================] - 1s 836us/step - loss: 0.3161 - accuracy: 0.9239 - val_loss: 0.8543 - val_accuracy: 0.7515\n",
      "Epoch 39/300\n",
      "681/681 [==============================] - 1s 809us/step - loss: 0.3049 - accuracy: 0.9221 - val_loss: 0.8483 - val_accuracy: 0.7521\n",
      "Epoch 40/300\n",
      "681/681 [==============================] - 1s 823us/step - loss: 0.3170 - accuracy: 0.9210 - val_loss: 0.8241 - val_accuracy: 0.7521\n",
      "67/67 [==============================] - 0s 683us/step - loss: 0.7960 - accuracy: 0.7753\n",
      "Finished Model_4, got results: test_loss=0.7960423231124878, test_acc=0.7752703428268433\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 2.1079 - accuracy: 0.6283 - val_loss: 1.0022 - val_accuracy: 0.6592\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.9065 - accuracy: 0.6704 - val_loss: 0.8860 - val_accuracy: 0.6833\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8109 - accuracy: 0.6966 - val_loss: 0.7962 - val_accuracy: 0.6780\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7612 - accuracy: 0.7069 - val_loss: 0.7551 - val_accuracy: 0.7039\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7401 - accuracy: 0.7105 - val_loss: 0.7521 - val_accuracy: 0.6962\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7277 - accuracy: 0.7219 - val_loss: 0.7734 - val_accuracy: 0.7039\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7182 - accuracy: 0.7236 - val_loss: 0.7331 - val_accuracy: 0.6898\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7125 - accuracy: 0.7239 - val_loss: 0.7218 - val_accuracy: 0.7162\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7012 - accuracy: 0.7264 - val_loss: 0.7323 - val_accuracy: 0.7068\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7005 - accuracy: 0.7267 - val_loss: 0.7414 - val_accuracy: 0.7033\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7007 - accuracy: 0.7227 - val_loss: 0.7319 - val_accuracy: 0.7056\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6944 - accuracy: 0.7330 - val_loss: 0.7319 - val_accuracy: 0.7039\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6958 - accuracy: 0.7314 - val_loss: 0.7807 - val_accuracy: 0.6698\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6996 - accuracy: 0.7274 - val_loss: 0.7262 - val_accuracy: 0.7068\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6927 - accuracy: 0.7267 - val_loss: 0.7428 - val_accuracy: 0.6957\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6959 - accuracy: 0.7344 - val_loss: 0.7280 - val_accuracy: 0.7009\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6939 - accuracy: 0.7311 - val_loss: 0.7356 - val_accuracy: 0.7015\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6977 - accuracy: 0.7326 - val_loss: 0.7325 - val_accuracy: 0.6939\n",
      "67/67 [==============================] - 0s 603us/step - loss: 0.7338 - accuracy: 0.6916\n",
      "Finished Model_5, got results: test_loss=0.7338239550590515, test_acc=0.6915844082832336\n",
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_KlekFP-MACCSFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 2.9594 - accuracy: 0.6669 - val_loss: 1.4609 - val_accuracy: 0.6880\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.2228 - accuracy: 0.7056 - val_loss: 1.1277 - val_accuracy: 0.7192\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0806 - accuracy: 0.7304 - val_loss: 1.1044 - val_accuracy: 0.7133\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0409 - accuracy: 0.7352 - val_loss: 1.0072 - val_accuracy: 0.7350\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0038 - accuracy: 0.7392 - val_loss: 1.0252 - val_accuracy: 0.7291\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9950 - accuracy: 0.7443 - val_loss: 1.0012 - val_accuracy: 0.7333\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9698 - accuracy: 0.7395 - val_loss: 0.9876 - val_accuracy: 0.7327\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9604 - accuracy: 0.7448 - val_loss: 1.0012 - val_accuracy: 0.7297\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 3s 5ms/step - loss: 0.9508 - accuracy: 0.7423 - val_loss: 0.9703 - val_accuracy: 0.7438\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 3s 5ms/step - loss: 0.9593 - accuracy: 0.7489 - val_loss: 1.0395 - val_accuracy: 0.7239\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9402 - accuracy: 0.7430 - val_loss: 1.0062 - val_accuracy: 0.7256\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9495 - accuracy: 0.7451 - val_loss: 0.9631 - val_accuracy: 0.7221\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9278 - accuracy: 0.7529 - val_loss: 0.9675 - val_accuracy: 0.7427\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9263 - accuracy: 0.7508 - val_loss: 0.9636 - val_accuracy: 0.7338\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9182 - accuracy: 0.7520 - val_loss: 0.9546 - val_accuracy: 0.7509\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9018 - accuracy: 0.7543 - val_loss: 0.9631 - val_accuracy: 0.7215\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9146 - accuracy: 0.7512 - val_loss: 0.9350 - val_accuracy: 0.7291\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8891 - accuracy: 0.7584 - val_loss: 0.9582 - val_accuracy: 0.7380\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9090 - accuracy: 0.7542 - val_loss: 0.9872 - val_accuracy: 0.7432\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8965 - accuracy: 0.7464 - val_loss: 0.9333 - val_accuracy: 0.7333\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8921 - accuracy: 0.7561 - val_loss: 0.9124 - val_accuracy: 0.7468\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8834 - accuracy: 0.7517 - val_loss: 0.9780 - val_accuracy: 0.7391\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8899 - accuracy: 0.7546 - val_loss: 0.9120 - val_accuracy: 0.7432\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8614 - accuracy: 0.7587 - val_loss: 0.9016 - val_accuracy: 0.7315\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8762 - accuracy: 0.7537 - val_loss: 0.9392 - val_accuracy: 0.7268\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.9841 - accuracy: 0.7142\n",
      "Finished Model_1, got results: test_loss=0.9840685129165649, test_acc=0.7141513824462891\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 4s 5ms/step - loss: 5.1304 - accuracy: 0.5053 - val_loss: 1.0120 - val_accuracy: 0.5018\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 3s 5ms/step - loss: 1.0118 - accuracy: 0.5025 - val_loss: 1.0130 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 3s 5ms/step - loss: 1.0120 - accuracy: 0.5025 - val_loss: 1.0119 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0121 - accuracy: 0.4978 - val_loss: 1.0132 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0122 - accuracy: 0.5025 - val_loss: 1.0111 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0122 - accuracy: 0.4954 - val_loss: 1.0127 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0121 - accuracy: 0.5013 - val_loss: 1.0124 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0122 - accuracy: 0.5004 - val_loss: 1.0126 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0122 - accuracy: 0.5025 - val_loss: 1.0111 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0122 - accuracy: 0.4987 - val_loss: 1.0128 - val_accuracy: 0.5018\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0122 - accuracy: 0.5025 - val_loss: 1.0117 - val_accuracy: 0.5018\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.0115 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=1.0114799737930298, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 1.0680 - accuracy: 0.6556 - val_loss: 0.6562 - val_accuracy: 0.7450\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 929us/step - loss: 0.5614 - accuracy: 0.7695 - val_loss: 0.5863 - val_accuracy: 0.7662\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.8156 - val_loss: 0.5849 - val_accuracy: 0.7579\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4259 - accuracy: 0.8304 - val_loss: 0.6061 - val_accuracy: 0.7685\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4012 - accuracy: 0.8526 - val_loss: 0.6165 - val_accuracy: 0.7662\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3772 - accuracy: 0.8650 - val_loss: 0.6517 - val_accuracy: 0.7697\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 967us/step - loss: 0.3718 - accuracy: 0.8703 - val_loss: 0.6625 - val_accuracy: 0.7685\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 998us/step - loss: 0.3487 - accuracy: 0.8863 - val_loss: 0.7033 - val_accuracy: 0.7673\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1000us/step - loss: 0.3411 - accuracy: 0.8930 - val_loss: 0.6703 - val_accuracy: 0.7709\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 976us/step - loss: 0.3292 - accuracy: 0.8949 - val_loss: 0.6807 - val_accuracy: 0.7761\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 985us/step - loss: 0.3193 - accuracy: 0.9020 - val_loss: 0.7130 - val_accuracy: 0.7785\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 993us/step - loss: 0.3210 - accuracy: 0.9020 - val_loss: 0.7481 - val_accuracy: 0.7709\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 956us/step - loss: 0.3095 - accuracy: 0.9086 - val_loss: 0.7150 - val_accuracy: 0.7785\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 982us/step - loss: 0.3005 - accuracy: 0.9105 - val_loss: 0.7513 - val_accuracy: 0.7703\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 975us/step - loss: 0.3089 - accuracy: 0.9108 - val_loss: 0.7624 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 935us/step - loss: 0.3037 - accuracy: 0.9186 - val_loss: 0.7582 - val_accuracy: 0.7773\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 909us/step - loss: 0.2928 - accuracy: 0.9198 - val_loss: 0.7777 - val_accuracy: 0.7726\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 933us/step - loss: 0.3011 - accuracy: 0.9174 - val_loss: 0.7763 - val_accuracy: 0.7791\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 907us/step - loss: 0.2938 - accuracy: 0.9220 - val_loss: 0.7858 - val_accuracy: 0.7773\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 901us/step - loss: 0.2802 - accuracy: 0.9251 - val_loss: 0.8181 - val_accuracy: 0.7797\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 881us/step - loss: 0.2888 - accuracy: 0.9252 - val_loss: 0.8173 - val_accuracy: 0.7679\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 869us/step - loss: 0.2854 - accuracy: 0.9233 - val_loss: 0.8251 - val_accuracy: 0.7797\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 905us/step - loss: 0.2752 - accuracy: 0.9298 - val_loss: 0.8523 - val_accuracy: 0.7691\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 887us/step - loss: 0.2898 - accuracy: 0.9264 - val_loss: 0.7961 - val_accuracy: 0.7820\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 882us/step - loss: 0.2667 - accuracy: 0.9334 - val_loss: 0.8297 - val_accuracy: 0.7791\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 878us/step - loss: 0.2763 - accuracy: 0.9308 - val_loss: 0.8306 - val_accuracy: 0.7855\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 878us/step - loss: 0.2711 - accuracy: 0.9309 - val_loss: 0.8698 - val_accuracy: 0.7714\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 882us/step - loss: 0.2688 - accuracy: 0.9406 - val_loss: 0.8570 - val_accuracy: 0.7679\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 1s 890us/step - loss: 0.2707 - accuracy: 0.9337 - val_loss: 0.8490 - val_accuracy: 0.7714\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 1s 882us/step - loss: 0.2617 - accuracy: 0.9373 - val_loss: 0.8470 - val_accuracy: 0.7738\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 1s 871us/step - loss: 0.2671 - accuracy: 0.9327 - val_loss: 0.8471 - val_accuracy: 0.7697\n",
      "Epoch 32/300\n",
      "681/681 [==============================] - 1s 882us/step - loss: 0.2719 - accuracy: 0.9329 - val_loss: 0.8384 - val_accuracy: 0.7750\n",
      "Epoch 33/300\n",
      "681/681 [==============================] - 1s 879us/step - loss: 0.2612 - accuracy: 0.9346 - val_loss: 0.8294 - val_accuracy: 0.7779\n",
      "Epoch 34/300\n",
      "681/681 [==============================] - 1s 874us/step - loss: 0.2551 - accuracy: 0.9383 - val_loss: 0.8657 - val_accuracy: 0.7744\n",
      "Epoch 35/300\n",
      "681/681 [==============================] - 1s 883us/step - loss: 0.2619 - accuracy: 0.9342 - val_loss: 0.8626 - val_accuracy: 0.7803\n",
      "Epoch 36/300\n",
      "681/681 [==============================] - 1s 878us/step - loss: 0.2579 - accuracy: 0.9368 - val_loss: 0.8470 - val_accuracy: 0.7761\n",
      "67/67 [==============================] - 0s 754us/step - loss: 0.8093 - accuracy: 0.7724\n",
      "Finished Model_3, got results: test_loss=0.8092711567878723, test_acc=0.7724494338035583\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6328 - accuracy: 0.7064 - val_loss: 0.5773 - val_accuracy: 0.7450\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4997 - accuracy: 0.8043 - val_loss: 0.5725 - val_accuracy: 0.7632\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.8423 - val_loss: 0.6007 - val_accuracy: 0.7779\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4047 - accuracy: 0.8642 - val_loss: 0.6225 - val_accuracy: 0.7867\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3789 - accuracy: 0.8829 - val_loss: 0.6592 - val_accuracy: 0.7709\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.8898 - val_loss: 0.6567 - val_accuracy: 0.7873\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.9010 - val_loss: 0.6924 - val_accuracy: 0.7797\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3433 - accuracy: 0.9048 - val_loss: 0.7205 - val_accuracy: 0.7697\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3362 - accuracy: 0.9085 - val_loss: 0.7064 - val_accuracy: 0.7832\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3273 - accuracy: 0.9123 - val_loss: 0.7072 - val_accuracy: 0.7826\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3206 - accuracy: 0.9176 - val_loss: 0.7599 - val_accuracy: 0.7697\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3135 - accuracy: 0.9182 - val_loss: 0.7330 - val_accuracy: 0.7738\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3097 - accuracy: 0.9189 - val_loss: 0.7515 - val_accuracy: 0.7791\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3118 - accuracy: 0.9229 - val_loss: 0.8136 - val_accuracy: 0.7591\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3038 - accuracy: 0.9262 - val_loss: 0.7811 - val_accuracy: 0.7750\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2932 - accuracy: 0.9277 - val_loss: 0.7826 - val_accuracy: 0.7756\n",
      "67/67 [==============================] - 0s 944us/step - loss: 0.7019 - accuracy: 0.7541\n",
      "Finished Model_4, got results: test_loss=0.7018926739692688, test_acc=0.7541137933731079\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.9373 - accuracy: 0.6631 - val_loss: 1.1838 - val_accuracy: 0.7021\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 1.0678 - accuracy: 0.7110 - val_loss: 1.0285 - val_accuracy: 0.7133\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.9841 - accuracy: 0.7311 - val_loss: 0.9265 - val_accuracy: 0.7315\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.9228 - accuracy: 0.7371 - val_loss: 0.9564 - val_accuracy: 0.7086\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8953 - accuracy: 0.7405 - val_loss: 0.9208 - val_accuracy: 0.7280\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8945 - accuracy: 0.7467 - val_loss: 0.9228 - val_accuracy: 0.7409\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8782 - accuracy: 0.7488 - val_loss: 0.8757 - val_accuracy: 0.7474\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8734 - accuracy: 0.7488 - val_loss: 0.8985 - val_accuracy: 0.7162\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8684 - accuracy: 0.7511 - val_loss: 0.8792 - val_accuracy: 0.7479\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8600 - accuracy: 0.7564 - val_loss: 0.8809 - val_accuracy: 0.7315\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8530 - accuracy: 0.7479 - val_loss: 0.8813 - val_accuracy: 0.7309\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8457 - accuracy: 0.7465 - val_loss: 0.8752 - val_accuracy: 0.7374\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8637 - accuracy: 0.7473 - val_loss: 0.8806 - val_accuracy: 0.7227\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8403 - accuracy: 0.7508 - val_loss: 0.8762 - val_accuracy: 0.7444\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8410 - accuracy: 0.7527 - val_loss: 0.8752 - val_accuracy: 0.7256\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8599 - accuracy: 0.7536 - val_loss: 0.8973 - val_accuracy: 0.7303\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8368 - accuracy: 0.7514 - val_loss: 0.8668 - val_accuracy: 0.7368\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8484 - accuracy: 0.7463 - val_loss: 0.8778 - val_accuracy: 0.7485\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8426 - accuracy: 0.7562 - val_loss: 0.8904 - val_accuracy: 0.7268\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8336 - accuracy: 0.7551 - val_loss: 0.8892 - val_accuracy: 0.7403\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8532 - accuracy: 0.7608 - val_loss: 0.9128 - val_accuracy: 0.7280\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8395 - accuracy: 0.7617 - val_loss: 0.8813 - val_accuracy: 0.7315\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.7580 - val_loss: 0.8705 - val_accuracy: 0.7444\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8496 - accuracy: 0.7611 - val_loss: 0.8755 - val_accuracy: 0.7280\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8247 - accuracy: 0.7587 - val_loss: 0.8851 - val_accuracy: 0.7444\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8436 - accuracy: 0.7611 - val_loss: 0.8427 - val_accuracy: 0.7450\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8263 - accuracy: 0.7542 - val_loss: 0.8863 - val_accuracy: 0.7309\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.8252 - accuracy: 0.7662 - val_loss: 0.8954 - val_accuracy: 0.7268\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.9041 - accuracy: 0.7221\n",
      "Finished Model_5, got results: test_loss=0.9041385054588318, test_acc=0.7221438884735107\n",
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_KlekFP-ExtFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 3.6325 - accuracy: 0.6422 - val_loss: 1.7581 - val_accuracy: 0.6575\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.3167 - accuracy: 0.6979 - val_loss: 1.2472 - val_accuracy: 0.7056\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.1255 - accuracy: 0.7214 - val_loss: 1.0887 - val_accuracy: 0.6945\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0659 - accuracy: 0.7210 - val_loss: 1.0915 - val_accuracy: 0.7103\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0424 - accuracy: 0.7341 - val_loss: 1.0573 - val_accuracy: 0.7074\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0217 - accuracy: 0.7307 - val_loss: 1.0231 - val_accuracy: 0.7186\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0073 - accuracy: 0.7404 - val_loss: 1.0170 - val_accuracy: 0.7150\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9998 - accuracy: 0.7402 - val_loss: 1.0229 - val_accuracy: 0.7145\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0118 - accuracy: 0.7382 - val_loss: 1.0528 - val_accuracy: 0.6992\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0070 - accuracy: 0.7410 - val_loss: 1.0259 - val_accuracy: 0.7192\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 4s 5ms/step - loss: 0.9975 - accuracy: 0.7467 - val_loss: 1.0129 - val_accuracy: 0.7192\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 1.0050 - accuracy: 0.7455 - val_loss: 1.0014 - val_accuracy: 0.7291\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 4s 6ms/step - loss: 0.9966 - accuracy: 0.7402 - val_loss: 1.0423 - val_accuracy: 0.7209\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 3s 5ms/step - loss: 0.9753 - accuracy: 0.7470 - val_loss: 1.0598 - val_accuracy: 0.7051\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0087 - accuracy: 0.7476 - val_loss: 1.0359 - val_accuracy: 0.7180\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9805 - accuracy: 0.7489 - val_loss: 1.0265 - val_accuracy: 0.7127\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9725 - accuracy: 0.7502 - val_loss: 1.0309 - val_accuracy: 0.7180\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9859 - accuracy: 0.7398 - val_loss: 0.9956 - val_accuracy: 0.7127\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9662 - accuracy: 0.7511 - val_loss: 0.9974 - val_accuracy: 0.7338\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9822 - accuracy: 0.7471 - val_loss: 1.0198 - val_accuracy: 0.7109\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 0.9713 - accuracy: 0.7426 - val_loss: 1.0074 - val_accuracy: 0.7397\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 2s 4ms/step - loss: 0.9660 - accuracy: 0.7414 - val_loss: 1.0802 - val_accuracy: 0.7139\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 2s 4ms/step - loss: 0.9756 - accuracy: 0.7454 - val_loss: 1.0187 - val_accuracy: 0.7203\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9736 - accuracy: 0.7465 - val_loss: 1.0135 - val_accuracy: 0.7233\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9709 - accuracy: 0.7529 - val_loss: 1.0021 - val_accuracy: 0.7098\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9713 - accuracy: 0.7455 - val_loss: 1.0136 - val_accuracy: 0.7309\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9660 - accuracy: 0.7436 - val_loss: 1.0009 - val_accuracy: 0.7227\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9566 - accuracy: 0.7535 - val_loss: 1.0376 - val_accuracy: 0.7086\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9693 - accuracy: 0.7535 - val_loss: 0.9946 - val_accuracy: 0.7127\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9622 - accuracy: 0.7471 - val_loss: 1.0104 - val_accuracy: 0.7162\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9631 - accuracy: 0.7443 - val_loss: 1.0282 - val_accuracy: 0.7156\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.0196 - accuracy: 0.7142\n",
      "Finished Model_1, got results: test_loss=1.019609808921814, test_acc=0.7141513824462891\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 3s 5ms/step - loss: 5.2683 - accuracy: 0.4984 - val_loss: 1.0767 - val_accuracy: 0.5018\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0776 - accuracy: 0.4993 - val_loss: 1.0783 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0779 - accuracy: 0.5004 - val_loss: 1.0779 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0780 - accuracy: 0.4957 - val_loss: 1.0796 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.5001 - val_loss: 1.0778 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.4990 - val_loss: 1.0791 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.4987 - val_loss: 1.0771 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.5025 - val_loss: 1.0776 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.5001 - val_loss: 1.0771 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.5025 - val_loss: 1.0790 - val_accuracy: 0.5018\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0781 - accuracy: 0.5010 - val_loss: 1.0779 - val_accuracy: 0.5018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 1.0766 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=1.0765783786773682, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7105 - accuracy: 0.7051 - val_loss: 0.6783 - val_accuracy: 0.7291\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4638 - accuracy: 0.8046 - val_loss: 0.5949 - val_accuracy: 0.7638\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4105 - accuracy: 0.8466 - val_loss: 0.5847 - val_accuracy: 0.7750\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3788 - accuracy: 0.8588 - val_loss: 0.6417 - val_accuracy: 0.7761\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3605 - accuracy: 0.8698 - val_loss: 0.6281 - val_accuracy: 0.7732\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3318 - accuracy: 0.8869 - val_loss: 0.6809 - val_accuracy: 0.7650\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3312 - accuracy: 0.8888 - val_loss: 0.6811 - val_accuracy: 0.7656\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3155 - accuracy: 0.9038 - val_loss: 0.7037 - val_accuracy: 0.7785\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3108 - accuracy: 0.9055 - val_loss: 0.7128 - val_accuracy: 0.7761\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3081 - accuracy: 0.9074 - val_loss: 0.7024 - val_accuracy: 0.7685\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2990 - accuracy: 0.9138 - val_loss: 0.7239 - val_accuracy: 0.7709\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2853 - accuracy: 0.9195 - val_loss: 0.7397 - val_accuracy: 0.7697\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2848 - accuracy: 0.9186 - val_loss: 0.7647 - val_accuracy: 0.7714\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2950 - accuracy: 0.9161 - val_loss: 0.7738 - val_accuracy: 0.7750\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2790 - accuracy: 0.9249 - val_loss: 0.8202 - val_accuracy: 0.7714\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2731 - accuracy: 0.9279 - val_loss: 0.8049 - val_accuracy: 0.7785\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2703 - accuracy: 0.9271 - val_loss: 0.8322 - val_accuracy: 0.7609\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2704 - accuracy: 0.9287 - val_loss: 0.8408 - val_accuracy: 0.7691\n",
      "67/67 [==============================] - 0s 756us/step - loss: 0.7408 - accuracy: 0.7776\n",
      "Finished Model_3, got results: test_loss=0.7408156394958496, test_acc=0.7776210904121399\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7138 - accuracy: 0.6895 - val_loss: 0.6126 - val_accuracy: 0.7380\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.5230 - accuracy: 0.7987 - val_loss: 0.6001 - val_accuracy: 0.7609\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.8454 - val_loss: 0.6074 - val_accuracy: 0.7662\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4201 - accuracy: 0.8635 - val_loss: 0.6671 - val_accuracy: 0.7709\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4123 - accuracy: 0.8710 - val_loss: 0.6632 - val_accuracy: 0.7644\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8820 - val_loss: 0.6989 - val_accuracy: 0.7709\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3811 - accuracy: 0.8879 - val_loss: 0.6922 - val_accuracy: 0.7750\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8960 - val_loss: 0.7171 - val_accuracy: 0.7697\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8966 - val_loss: 0.6957 - val_accuracy: 0.7703\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.9026 - val_loss: 0.7202 - val_accuracy: 0.7879\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3560 - accuracy: 0.9066 - val_loss: 0.7061 - val_accuracy: 0.7844\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.9105 - val_loss: 0.7521 - val_accuracy: 0.7744\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.9095 - val_loss: 0.7662 - val_accuracy: 0.7732\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.9102 - val_loss: 0.8197 - val_accuracy: 0.7691\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.9157 - val_loss: 0.7597 - val_accuracy: 0.7797\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.9193 - val_loss: 0.7947 - val_accuracy: 0.7726\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.9187 - val_loss: 0.8129 - val_accuracy: 0.7773\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.9229 - val_loss: 0.7882 - val_accuracy: 0.7779\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3176 - accuracy: 0.9193 - val_loss: 0.8116 - val_accuracy: 0.7709\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.9224 - val_loss: 0.8450 - val_accuracy: 0.7750\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.7588\n",
      "Finished Model_4, got results: test_loss=0.7353614568710327, test_acc=0.7588152289390564\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 2.3836 - accuracy: 0.6563 - val_loss: 1.3740 - val_accuracy: 0.6827\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.1736 - accuracy: 0.7009 - val_loss: 1.0550 - val_accuracy: 0.7068\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.7107 - val_loss: 1.0342 - val_accuracy: 0.7004\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9757 - accuracy: 0.7299 - val_loss: 1.0000 - val_accuracy: 0.7156\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9632 - accuracy: 0.7326 - val_loss: 0.9899 - val_accuracy: 0.7109\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9393 - accuracy: 0.7349 - val_loss: 0.9499 - val_accuracy: 0.7192\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9242 - accuracy: 0.7294 - val_loss: 0.9287 - val_accuracy: 0.7203\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9099 - accuracy: 0.7396 - val_loss: 0.9493 - val_accuracy: 0.7291\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8927 - accuracy: 0.7448 - val_loss: 0.9186 - val_accuracy: 0.7045\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8947 - accuracy: 0.7383 - val_loss: 0.9502 - val_accuracy: 0.7239\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8841 - accuracy: 0.7471 - val_loss: 0.9096 - val_accuracy: 0.7139\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8901 - accuracy: 0.7424 - val_loss: 0.9015 - val_accuracy: 0.7286\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8786 - accuracy: 0.7439 - val_loss: 0.8867 - val_accuracy: 0.7315\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 2s 4ms/step - loss: 0.8694 - accuracy: 0.7464 - val_loss: 0.9098 - val_accuracy: 0.7121\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8696 - accuracy: 0.7455 - val_loss: 0.9073 - val_accuracy: 0.7274\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8739 - accuracy: 0.7461 - val_loss: 0.9170 - val_accuracy: 0.7074\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8749 - accuracy: 0.7443 - val_loss: 0.8968 - val_accuracy: 0.7192\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8760 - accuracy: 0.7496 - val_loss: 0.9520 - val_accuracy: 0.7092\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8680 - accuracy: 0.7571 - val_loss: 0.8991 - val_accuracy: 0.7315\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8725 - accuracy: 0.7515 - val_loss: 0.9227 - val_accuracy: 0.7209\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8706 - accuracy: 0.7567 - val_loss: 0.8940 - val_accuracy: 0.7297\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8681 - accuracy: 0.7530 - val_loss: 0.9248 - val_accuracy: 0.7162\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8675 - accuracy: 0.7543 - val_loss: 0.8810 - val_accuracy: 0.7415\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8510 - accuracy: 0.7543 - val_loss: 0.8928 - val_accuracy: 0.7268\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8652 - accuracy: 0.7558 - val_loss: 0.9012 - val_accuracy: 0.7244\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8666 - accuracy: 0.7579 - val_loss: 0.9004 - val_accuracy: 0.7344\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8658 - accuracy: 0.7526 - val_loss: 0.8993 - val_accuracy: 0.7256\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8652 - accuracy: 0.7558 - val_loss: 0.8914 - val_accuracy: 0.7092\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.8517 - accuracy: 0.7537 - val_loss: 0.8985 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8551 - accuracy: 0.7529 - val_loss: 0.8989 - val_accuracy: 0.7244\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8652 - accuracy: 0.7560 - val_loss: 0.9038 - val_accuracy: 0.7250\n",
      "Epoch 32/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8634 - accuracy: 0.7576 - val_loss: 0.9137 - val_accuracy: 0.7215\n",
      "Epoch 33/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.8572 - accuracy: 0.7634 - val_loss: 0.8809 - val_accuracy: 0.7244\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.7226\n",
      "Finished Model_5, got results: test_loss=0.9027656316757202, test_acc=0.7226139903068542\n",
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_MACCSFP-ExtFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 3.3481 - accuracy: 0.6362 - val_loss: 1.1310 - val_accuracy: 0.6722\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.0025 - accuracy: 0.6825 - val_loss: 0.9693 - val_accuracy: 0.6968\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9001 - accuracy: 0.7078 - val_loss: 0.8749 - val_accuracy: 0.7150\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8496 - accuracy: 0.7182 - val_loss: 0.8713 - val_accuracy: 0.7197\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8432 - accuracy: 0.7267 - val_loss: 0.8359 - val_accuracy: 0.7145\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8249 - accuracy: 0.7286 - val_loss: 0.8342 - val_accuracy: 0.7145\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7974 - accuracy: 0.7295 - val_loss: 0.8020 - val_accuracy: 0.7239\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7916 - accuracy: 0.7370 - val_loss: 0.8143 - val_accuracy: 0.7115\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7775 - accuracy: 0.7289 - val_loss: 0.8049 - val_accuracy: 0.7062\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7739 - accuracy: 0.7308 - val_loss: 0.8178 - val_accuracy: 0.7056\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7682 - accuracy: 0.7399 - val_loss: 0.7950 - val_accuracy: 0.7127\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7642 - accuracy: 0.7366 - val_loss: 0.8016 - val_accuracy: 0.7227\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7562 - accuracy: 0.7370 - val_loss: 0.7920 - val_accuracy: 0.7239\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7630 - accuracy: 0.7443 - val_loss: 0.8039 - val_accuracy: 0.7244\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7665 - accuracy: 0.7395 - val_loss: 0.8452 - val_accuracy: 0.7051\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7473 - accuracy: 0.7465 - val_loss: 0.7982 - val_accuracy: 0.7192\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7596 - accuracy: 0.7480 - val_loss: 0.8117 - val_accuracy: 0.7256\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7597 - accuracy: 0.7465 - val_loss: 0.8206 - val_accuracy: 0.7109\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7468 - accuracy: 0.7458 - val_loss: 0.7858 - val_accuracy: 0.7174\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7454 - accuracy: 0.7483 - val_loss: 0.8124 - val_accuracy: 0.7121\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7480 - accuracy: 0.7464 - val_loss: 0.7773 - val_accuracy: 0.7280\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7585 - accuracy: 0.7452 - val_loss: 0.8086 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.7460 - val_loss: 0.8004 - val_accuracy: 0.7127\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7459 - accuracy: 0.7430 - val_loss: 0.7950 - val_accuracy: 0.7309\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7390 - accuracy: 0.7515 - val_loss: 0.7871 - val_accuracy: 0.7139\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7398 - accuracy: 0.7502 - val_loss: 0.7936 - val_accuracy: 0.7203\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7483 - accuracy: 0.7533 - val_loss: 0.7852 - val_accuracy: 0.7180\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7434 - accuracy: 0.7483 - val_loss: 0.7795 - val_accuracy: 0.7239\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7418 - accuracy: 0.7501 - val_loss: 0.7868 - val_accuracy: 0.7209\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7308 - accuracy: 0.7518 - val_loss: 0.8075 - val_accuracy: 0.7162\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7339 - accuracy: 0.7499 - val_loss: 0.7615 - val_accuracy: 0.7327\n",
      "Epoch 32/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7303 - accuracy: 0.7488 - val_loss: 0.7722 - val_accuracy: 0.7215\n",
      "Epoch 33/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7282 - accuracy: 0.7510 - val_loss: 0.7886 - val_accuracy: 0.7244\n",
      "Epoch 34/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7340 - accuracy: 0.7458 - val_loss: 0.7902 - val_accuracy: 0.7227\n",
      "Epoch 35/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7347 - accuracy: 0.7508 - val_loss: 0.7672 - val_accuracy: 0.7239\n",
      "Epoch 36/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7266 - accuracy: 0.7593 - val_loss: 0.7745 - val_accuracy: 0.7297\n",
      "Epoch 37/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7339 - accuracy: 0.7521 - val_loss: 0.7776 - val_accuracy: 0.7280\n",
      "Epoch 38/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7308 - accuracy: 0.7476 - val_loss: 0.7655 - val_accuracy: 0.7397\n",
      "Epoch 39/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7322 - accuracy: 0.7524 - val_loss: 0.8598 - val_accuracy: 0.7262\n",
      "Epoch 40/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7375 - accuracy: 0.7467 - val_loss: 0.7785 - val_accuracy: 0.7256\n",
      "Epoch 41/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7268 - accuracy: 0.7530 - val_loss: 0.7791 - val_accuracy: 0.7268\n",
      "Epoch 42/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7302 - accuracy: 0.7517 - val_loss: 0.7666 - val_accuracy: 0.7203\n",
      "Epoch 43/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7239 - accuracy: 0.7524 - val_loss: 0.7754 - val_accuracy: 0.7244\n",
      "Epoch 44/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7262 - accuracy: 0.7517 - val_loss: 0.7747 - val_accuracy: 0.7280\n",
      "Epoch 45/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7283 - accuracy: 0.7554 - val_loss: 0.7654 - val_accuracy: 0.7262\n",
      "Epoch 46/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7227 - accuracy: 0.7527 - val_loss: 0.7638 - val_accuracy: 0.7215\n",
      "Epoch 47/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7261 - accuracy: 0.7530 - val_loss: 0.7670 - val_accuracy: 0.7156\n",
      "Epoch 48/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7252 - accuracy: 0.7512 - val_loss: 0.7669 - val_accuracy: 0.7315\n",
      "67/67 [==============================] - 0s 879us/step - loss: 0.7774 - accuracy: 0.7240\n",
      "Finished Model_1, got results: test_loss=0.7773562669754028, test_acc=0.7240244746208191\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 5.0590 - accuracy: 0.5031 - val_loss: 0.9262 - val_accuracy: 0.5018\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9263 - accuracy: 0.4972 - val_loss: 0.9262 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9265 - accuracy: 0.4916 - val_loss: 0.9262 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.4928 - val_loss: 0.9262 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9265 - accuracy: 0.4940 - val_loss: 0.9264 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.5025 - val_loss: 0.9269 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.4946 - val_loss: 0.9262 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.5025 - val_loss: 0.9266 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.5025 - val_loss: 0.9266 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.4984 - val_loss: 0.9264 - val_accuracy: 0.5018\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9264 - accuracy: 0.4949 - val_loss: 0.9262 - val_accuracy: 0.5018\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.9251 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=0.9250661730766296, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6909 - val_loss: 0.5569 - val_accuracy: 0.7544\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 757us/step - loss: 0.4894 - accuracy: 0.7847 - val_loss: 0.5634 - val_accuracy: 0.7597\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 882us/step - loss: 0.4405 - accuracy: 0.8155 - val_loss: 0.5316 - val_accuracy: 0.7703\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 807us/step - loss: 0.4137 - accuracy: 0.8354 - val_loss: 0.5744 - val_accuracy: 0.7509\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 746us/step - loss: 0.3910 - accuracy: 0.8491 - val_loss: 0.5768 - val_accuracy: 0.7667\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 747us/step - loss: 0.3757 - accuracy: 0.8616 - val_loss: 0.5845 - val_accuracy: 0.7703\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 756us/step - loss: 0.3533 - accuracy: 0.8731 - val_loss: 0.6144 - val_accuracy: 0.7638\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 744us/step - loss: 0.3483 - accuracy: 0.8767 - val_loss: 0.6370 - val_accuracy: 0.7656\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 749us/step - loss: 0.3330 - accuracy: 0.8872 - val_loss: 0.6487 - val_accuracy: 0.7732\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 874us/step - loss: 0.3262 - accuracy: 0.8898 - val_loss: 0.6660 - val_accuracy: 0.7620\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 746us/step - loss: 0.3161 - accuracy: 0.8992 - val_loss: 0.6618 - val_accuracy: 0.7597\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 750us/step - loss: 0.3142 - accuracy: 0.8996 - val_loss: 0.6769 - val_accuracy: 0.7697\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 804us/step - loss: 0.3126 - accuracy: 0.9013 - val_loss: 0.6649 - val_accuracy: 0.7773\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 840us/step - loss: 0.2989 - accuracy: 0.9102 - val_loss: 0.7001 - val_accuracy: 0.7662\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 931us/step - loss: 0.2964 - accuracy: 0.9101 - val_loss: 0.7128 - val_accuracy: 0.7650\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2937 - accuracy: 0.9165 - val_loss: 0.6984 - val_accuracy: 0.7738\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 873us/step - loss: 0.2890 - accuracy: 0.9158 - val_loss: 0.7115 - val_accuracy: 0.7691\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 956us/step - loss: 0.2873 - accuracy: 0.9199 - val_loss: 0.7478 - val_accuracy: 0.7573\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 767us/step - loss: 0.2860 - accuracy: 0.9199 - val_loss: 0.7444 - val_accuracy: 0.7609\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 900us/step - loss: 0.2806 - accuracy: 0.9212 - val_loss: 0.7310 - val_accuracy: 0.7738\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 806us/step - loss: 0.2891 - accuracy: 0.9186 - val_loss: 0.7718 - val_accuracy: 0.7626\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 975us/step - loss: 0.2799 - accuracy: 0.9217 - val_loss: 0.7805 - val_accuracy: 0.7679\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2761 - accuracy: 0.9273 - val_loss: 0.7678 - val_accuracy: 0.7714\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.7659\n",
      "Finished Model_3, got results: test_loss=0.6877798438072205, test_acc=0.7658674120903015\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.6647 - accuracy: 0.6912 - val_loss: 0.6065 - val_accuracy: 0.7432\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7836 - val_loss: 0.5936 - val_accuracy: 0.7579\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.8172 - val_loss: 0.5989 - val_accuracy: 0.7638\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.8379 - val_loss: 0.6308 - val_accuracy: 0.7509\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.8509 - val_loss: 0.6284 - val_accuracy: 0.7609\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8679 - val_loss: 0.6450 - val_accuracy: 0.7685\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3989 - accuracy: 0.8733 - val_loss: 0.6527 - val_accuracy: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.3872 - accuracy: 0.8828 - val_loss: 0.6574 - val_accuracy: 0.7662\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3860 - accuracy: 0.8852 - val_loss: 0.6802 - val_accuracy: 0.7615\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8930 - val_loss: 0.6909 - val_accuracy: 0.7709\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8982 - val_loss: 0.7335 - val_accuracy: 0.7626\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.9019 - val_loss: 0.7002 - val_accuracy: 0.7703\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3575 - accuracy: 0.9023 - val_loss: 0.7186 - val_accuracy: 0.7626\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.9049 - val_loss: 0.7000 - val_accuracy: 0.7797\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.9082 - val_loss: 0.7219 - val_accuracy: 0.7679\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3378 - accuracy: 0.9074 - val_loss: 0.7695 - val_accuracy: 0.7697\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.9070 - val_loss: 0.7408 - val_accuracy: 0.7650\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.9058 - val_loss: 0.7706 - val_accuracy: 0.7644\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.9185 - val_loss: 0.7830 - val_accuracy: 0.7550\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.9130 - val_loss: 0.8523 - val_accuracy: 0.7421\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3384 - accuracy: 0.9120 - val_loss: 0.7777 - val_accuracy: 0.7714\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3257 - accuracy: 0.9158 - val_loss: 0.8018 - val_accuracy: 0.7656\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.9204 - val_loss: 0.7813 - val_accuracy: 0.7626\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3281 - accuracy: 0.9154 - val_loss: 0.8243 - val_accuracy: 0.7720\n",
      "67/67 [==============================] - 0s 938us/step - loss: 0.7167 - accuracy: 0.7800\n",
      "Finished Model_4, got results: test_loss=0.7166955471038818, test_acc=0.7799717783927917\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 2.2365 - accuracy: 0.6606 - val_loss: 1.0698 - val_accuracy: 0.6733\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9226 - accuracy: 0.6895 - val_loss: 0.8861 - val_accuracy: 0.6927\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8435 - accuracy: 0.7085 - val_loss: 0.8120 - val_accuracy: 0.7192\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7913 - accuracy: 0.7183 - val_loss: 0.8478 - val_accuracy: 0.7056\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7718 - accuracy: 0.7294 - val_loss: 0.7749 - val_accuracy: 0.7121\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7470 - accuracy: 0.7311 - val_loss: 0.7883 - val_accuracy: 0.7027\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7392 - accuracy: 0.7335 - val_loss: 0.7723 - val_accuracy: 0.7039\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7274 - accuracy: 0.7282 - val_loss: 0.7664 - val_accuracy: 0.7080\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7234 - accuracy: 0.7252 - val_loss: 0.7474 - val_accuracy: 0.7080\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7149 - accuracy: 0.7269 - val_loss: 0.7325 - val_accuracy: 0.7227\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7124 - accuracy: 0.7266 - val_loss: 0.7384 - val_accuracy: 0.7150\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7080 - accuracy: 0.7370 - val_loss: 0.7361 - val_accuracy: 0.7156\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7083 - accuracy: 0.7332 - val_loss: 0.7484 - val_accuracy: 0.7121\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7050 - accuracy: 0.7297 - val_loss: 0.7723 - val_accuracy: 0.7074\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7087 - accuracy: 0.7360 - val_loss: 0.7324 - val_accuracy: 0.7062\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7134 - accuracy: 0.7342 - val_loss: 0.7729 - val_accuracy: 0.6962\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7041 - accuracy: 0.7367 - val_loss: 0.7429 - val_accuracy: 0.7103\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7043 - accuracy: 0.7368 - val_loss: 0.7440 - val_accuracy: 0.7168\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.7392 - val_loss: 0.7569 - val_accuracy: 0.7098\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7086 - accuracy: 0.7367 - val_loss: 0.7270 - val_accuracy: 0.7239\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7044 - accuracy: 0.7366 - val_loss: 0.7267 - val_accuracy: 0.7133\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7027 - accuracy: 0.7410 - val_loss: 0.7458 - val_accuracy: 0.7174\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7140 - accuracy: 0.7439 - val_loss: 0.7656 - val_accuracy: 0.7086\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7021 - accuracy: 0.7395 - val_loss: 0.7304 - val_accuracy: 0.7197\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.7000 - accuracy: 0.7410 - val_loss: 0.7543 - val_accuracy: 0.7203\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7025 - accuracy: 0.7455 - val_loss: 0.7398 - val_accuracy: 0.7015\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7018 - accuracy: 0.7401 - val_loss: 0.7431 - val_accuracy: 0.7303\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6987 - accuracy: 0.7418 - val_loss: 0.7419 - val_accuracy: 0.7127\n",
      "Epoch 29/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.7028 - accuracy: 0.7476 - val_loss: 0.7432 - val_accuracy: 0.7274\n",
      "Epoch 30/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6989 - accuracy: 0.7443 - val_loss: 0.7226 - val_accuracy: 0.7321\n",
      "Epoch 31/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6969 - accuracy: 0.7498 - val_loss: 0.7742 - val_accuracy: 0.7068\n",
      "Epoch 32/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6936 - accuracy: 0.7436 - val_loss: 0.7271 - val_accuracy: 0.7286\n",
      "Epoch 33/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6892 - accuracy: 0.7448 - val_loss: 0.7185 - val_accuracy: 0.7192\n",
      "Epoch 34/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6896 - accuracy: 0.7427 - val_loss: 0.7235 - val_accuracy: 0.7098\n",
      "Epoch 35/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6885 - accuracy: 0.7432 - val_loss: 0.7128 - val_accuracy: 0.7286\n",
      "Epoch 36/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6886 - accuracy: 0.7463 - val_loss: 0.7360 - val_accuracy: 0.7145\n",
      "Epoch 37/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.7483 - val_loss: 0.7432 - val_accuracy: 0.7045\n",
      "Epoch 38/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.7471 - val_loss: 0.7361 - val_accuracy: 0.7133\n",
      "Epoch 39/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.7455 - val_loss: 0.7204 - val_accuracy: 0.7250\n",
      "Epoch 40/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.7486 - val_loss: 0.7244 - val_accuracy: 0.7315\n",
      "67/67 [==============================] - 0s 917us/step - loss: 0.7325 - accuracy: 0.7076\n",
      "Finished Model_5, got results: test_loss=0.7325151562690735, test_acc=0.7075693607330322\n",
      "Running Deep Neural Network Tuner for C:\\Users\\SG0306249\\Downloads\\cardiotoxicity_prediction-main\\cardiotoxicity_prediction-main\\data\\preprocessed\\cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv\n",
      "Running Model_1\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 3.6507 - accuracy: 0.6560 - val_loss: 1.6180 - val_accuracy: 0.6675\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.3601 - accuracy: 0.7094 - val_loss: 1.2351 - val_accuracy: 0.7209\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.2030 - accuracy: 0.7086 - val_loss: 1.1748 - val_accuracy: 0.7092\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.1881 - accuracy: 0.7247 - val_loss: 1.2999 - val_accuracy: 0.7080\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.1056 - accuracy: 0.7341 - val_loss: 1.0663 - val_accuracy: 0.7156\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0637 - accuracy: 0.7258 - val_loss: 1.0611 - val_accuracy: 0.7192\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0368 - accuracy: 0.7305 - val_loss: 1.0270 - val_accuracy: 0.7145\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0180 - accuracy: 0.7298 - val_loss: 1.0253 - val_accuracy: 0.7203\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9994 - accuracy: 0.7360 - val_loss: 1.0240 - val_accuracy: 0.7215\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0191 - accuracy: 0.7338 - val_loss: 1.0631 - val_accuracy: 0.7268\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0016 - accuracy: 0.7392 - val_loss: 1.0239 - val_accuracy: 0.7250\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9879 - accuracy: 0.7360 - val_loss: 1.0497 - val_accuracy: 0.7356\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9812 - accuracy: 0.7357 - val_loss: 1.0123 - val_accuracy: 0.7045\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9780 - accuracy: 0.7427 - val_loss: 1.0028 - val_accuracy: 0.7327\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0036 - accuracy: 0.7418 - val_loss: 1.0569 - val_accuracy: 0.7186\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9852 - accuracy: 0.7364 - val_loss: 0.9848 - val_accuracy: 0.7356\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9589 - accuracy: 0.7486 - val_loss: 0.9981 - val_accuracy: 0.7350\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9639 - accuracy: 0.7492 - val_loss: 1.0336 - val_accuracy: 0.7315\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9803 - accuracy: 0.7498 - val_loss: 1.0152 - val_accuracy: 0.7209\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9681 - accuracy: 0.7465 - val_loss: 1.0186 - val_accuracy: 0.7262\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9599 - accuracy: 0.7507 - val_loss: 1.0059 - val_accuracy: 0.7280\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 0.9686 - accuracy: 0.7495 - val_loss: 1.0081 - val_accuracy: 0.7315\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 1.0667 - accuracy: 0.7094\n",
      "Finished Model_1, got results: test_loss=1.0666687488555908, test_acc=0.7094499468803406\n",
      "Running Model_2\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 5.2703 - accuracy: 0.5065 - val_loss: 1.0886 - val_accuracy: 0.4982\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0901 - accuracy: 0.4819 - val_loss: 1.0920 - val_accuracy: 0.5018\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0904 - accuracy: 0.4928 - val_loss: 1.0899 - val_accuracy: 0.5018\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.4984 - val_loss: 1.0916 - val_accuracy: 0.5018\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.4931 - val_loss: 1.0898 - val_accuracy: 0.5018\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.5025 - val_loss: 1.0910 - val_accuracy: 0.5018\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0907 - accuracy: 0.4943 - val_loss: 1.0893 - val_accuracy: 0.5018\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.4990 - val_loss: 1.0909 - val_accuracy: 0.5018\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.5025 - val_loss: 1.0891 - val_accuracy: 0.5018\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.5007 - val_loss: 1.0906 - val_accuracy: 0.4982\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.4931 - val_loss: 1.0898 - val_accuracy: 0.5018\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 1.0906 - accuracy: 0.4990 - val_loss: 1.0911 - val_accuracy: 0.5018\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.5242\n",
      "Finished Model_2, got results: test_loss=1.0920153856277466, test_acc=0.5242124795913696\n",
      "Running Model_3\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.9624 - accuracy: 0.6866 - val_loss: 0.6846 - val_accuracy: 0.7350\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7917 - val_loss: 0.6344 - val_accuracy: 0.7615\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.8385 - val_loss: 0.6147 - val_accuracy: 0.7632\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3913 - accuracy: 0.8589 - val_loss: 0.6697 - val_accuracy: 0.7697\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3675 - accuracy: 0.8697 - val_loss: 0.6490 - val_accuracy: 0.7714\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3537 - accuracy: 0.8845 - val_loss: 0.6649 - val_accuracy: 0.7756\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3367 - accuracy: 0.8939 - val_loss: 0.6916 - val_accuracy: 0.7756\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3366 - accuracy: 0.8964 - val_loss: 0.7445 - val_accuracy: 0.7632\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3203 - accuracy: 0.9102 - val_loss: 0.7102 - val_accuracy: 0.7756\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.9095 - val_loss: 0.7497 - val_accuracy: 0.7785\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3060 - accuracy: 0.9183 - val_loss: 0.7442 - val_accuracy: 0.7761\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2970 - accuracy: 0.9179 - val_loss: 0.7724 - val_accuracy: 0.7785\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3020 - accuracy: 0.9193 - val_loss: 0.7641 - val_accuracy: 0.7738\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2879 - accuracy: 0.9210 - val_loss: 0.7239 - val_accuracy: 0.7914\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3004 - accuracy: 0.9212 - val_loss: 0.7834 - val_accuracy: 0.7732\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2837 - accuracy: 0.9305 - val_loss: 0.7725 - val_accuracy: 0.7826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2809 - accuracy: 0.9305 - val_loss: 0.7583 - val_accuracy: 0.7908\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2781 - accuracy: 0.9301 - val_loss: 0.7745 - val_accuracy: 0.7838\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2760 - accuracy: 0.9292 - val_loss: 0.7953 - val_accuracy: 0.7820\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2809 - accuracy: 0.9345 - val_loss: 0.7807 - val_accuracy: 0.7861\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2698 - accuracy: 0.9337 - val_loss: 0.8131 - val_accuracy: 0.7697\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2614 - accuracy: 0.9370 - val_loss: 0.8678 - val_accuracy: 0.7656\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2681 - accuracy: 0.9324 - val_loss: 0.8236 - val_accuracy: 0.7750\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.2620 - accuracy: 0.9387 - val_loss: 0.8624 - val_accuracy: 0.7779\n",
      "67/67 [==============================] - 0s 944us/step - loss: 0.7713 - accuracy: 0.7734\n",
      "Finished Model_3, got results: test_loss=0.7713448405265808, test_acc=0.7733897566795349\n",
      "Running Model_4\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.6725 - accuracy: 0.7073 - val_loss: 0.6147 - val_accuracy: 0.7509\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.5108 - accuracy: 0.8097 - val_loss: 0.6138 - val_accuracy: 0.7656\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4578 - accuracy: 0.8416 - val_loss: 0.6231 - val_accuracy: 0.7662\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4261 - accuracy: 0.8617 - val_loss: 0.6427 - val_accuracy: 0.7714\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4119 - accuracy: 0.8711 - val_loss: 0.6656 - val_accuracy: 0.7797\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.4004 - accuracy: 0.8832 - val_loss: 0.6778 - val_accuracy: 0.7738\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3818 - accuracy: 0.8922 - val_loss: 0.6977 - val_accuracy: 0.7779\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3744 - accuracy: 0.8960 - val_loss: 0.7375 - val_accuracy: 0.7744\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8983 - val_loss: 0.7136 - val_accuracy: 0.7920\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.9020 - val_loss: 0.7605 - val_accuracy: 0.7744\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3648 - accuracy: 0.9026 - val_loss: 0.7592 - val_accuracy: 0.7685\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3650 - accuracy: 0.9046 - val_loss: 0.7235 - val_accuracy: 0.7685\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3556 - accuracy: 0.9126 - val_loss: 0.7124 - val_accuracy: 0.7832\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3542 - accuracy: 0.9113 - val_loss: 0.7477 - val_accuracy: 0.7744\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3415 - accuracy: 0.9139 - val_loss: 0.7476 - val_accuracy: 0.7844\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.9127 - val_loss: 0.7519 - val_accuracy: 0.7838\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3346 - accuracy: 0.9179 - val_loss: 0.7445 - val_accuracy: 0.7750\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.9192 - val_loss: 0.7823 - val_accuracy: 0.7779\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.9187 - val_loss: 0.7457 - val_accuracy: 0.7867\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.7630\n",
      "Finished Model_4, got results: test_loss=0.7509145140647888, test_acc=0.7630465626716614\n",
      "Running Model_5\n",
      "Epoch 1/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 2.4100 - accuracy: 0.6519 - val_loss: 1.4636 - val_accuracy: 0.6686\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.3030 - accuracy: 0.6888 - val_loss: 1.2066 - val_accuracy: 0.6962\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.1190 - accuracy: 0.7078 - val_loss: 1.1065 - val_accuracy: 0.7109\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.0244 - accuracy: 0.7295 - val_loss: 0.9995 - val_accuracy: 0.6998\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9751 - accuracy: 0.7289 - val_loss: 0.9554 - val_accuracy: 0.7092\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9402 - accuracy: 0.7301 - val_loss: 0.9174 - val_accuracy: 0.7362\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9403 - accuracy: 0.7357 - val_loss: 0.9419 - val_accuracy: 0.7203\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9089 - accuracy: 0.7355 - val_loss: 0.9130 - val_accuracy: 0.7303\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.9177 - accuracy: 0.7404 - val_loss: 0.9204 - val_accuracy: 0.7309\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8932 - accuracy: 0.7382 - val_loss: 0.9485 - val_accuracy: 0.7250\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8967 - accuracy: 0.7408 - val_loss: 0.9207 - val_accuracy: 0.7233\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8849 - accuracy: 0.7411 - val_loss: 0.8998 - val_accuracy: 0.7309\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8766 - accuracy: 0.7458 - val_loss: 0.8908 - val_accuracy: 0.7309\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8706 - accuracy: 0.7455 - val_loss: 0.9063 - val_accuracy: 0.7268\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8790 - accuracy: 0.7515 - val_loss: 0.9217 - val_accuracy: 0.7315\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 0.8873 - accuracy: 0.7443 - val_loss: 0.8988 - val_accuracy: 0.7327\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.7170\n",
      "Finished Model_5, got results: test_loss=0.9435443878173828, test_acc=0.7169722318649292\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSED_KLEKOTA_ROTH_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP.csv'\n",
    "PREPROCESSED_MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP.csv'\n",
    "PREPROCESSED_EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_ExtFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-ExtFP.csv'\n",
    "PREPROCESSED_MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP-ExtFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv'\n",
    "\n",
    "data_to_process = [\n",
    "    (PREPROCESSED_KLEKOTA_ROTH_DATA,),\n",
    "    (PREPROCESSED_MACCS_DATA,),\n",
    "    (PREPROCESSED_EXT_DATA,),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA,),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__EXT_DATA,),\n",
    "    (PREPROCESSED_MACCS__EXT_DATA,),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA,),\n",
    "]\n",
    "\n",
    "\n",
    "deepNeuralNetworkTuner = DeepNeuralNetworkTuner()\n",
    "\n",
    "for data in data_to_process:\n",
    "    deepNeuralNetworkTuner.apply(data[0])\n",
    "\n",
    "deepNeuralNetworkTuner.summary(RESULTS_DEEP_NEURAL_NETWORKS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
