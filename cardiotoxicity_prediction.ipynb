{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e86ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "import numbers\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaabe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.cwd()\n",
    "DATA_PATH = Path.cwd() / 'data'\n",
    "PREPROCESSED_DATA_PATH = DATA_PATH / 'preprocessed'\n",
    "RESULTS_DATA_PATH = PATH / 'results'\n",
    "SPLITTED_DATA_PATH = PREPROCESSED_DATA_PATH / 'splitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf15b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_KLEKOTA_ROTH_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP.csv'\n",
    "PREPROCESSED_MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP.csv'\n",
    "PREPROCESSED_EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_ExtFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-ExtFP.csv'\n",
    "PREPROCESSED_MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP-ExtFP.csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv'\n",
    "\n",
    "RESULTS_KLEKOTA_ROTH = RESULTS_DATA_PATH / 'KlekFP.csv'\n",
    "RESULTS_MACCS = RESULTS_DATA_PATH / 'MACCSFP.csv'\n",
    "RESULTS_EXT = RESULTS_DATA_PATH / 'ExtFP.csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS_DATA = RESULTS_DATA_PATH / 'KlekFP-MACCSFP.csv'\n",
    "RESULTS_KLEKOTA_ROTH__EXT_DATA = RESULTS_DATA_PATH / 'KlekFP-ExtFP.csv'\n",
    "RESULTS_MACCS__EXT_DATA = RESULTS_DATA_PATH / 'MACCSFP-ExtFP.csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA = RESULTS_DATA_PATH / 'KlekFP-MACCSFP-ExtFP.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e103cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_KLEKOTA_ROTH_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP[{}].csv'\n",
    "PREPROCESSED_MACCS_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_MACCSFP[{}].csv'\n",
    "PREPROCESSED_EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_ExtFP[{}].csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP-MACCSFP[{}].csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP-ExtFP[{}].csv'\n",
    "PREPROCESSED_MACCS__EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_MACCSFP-ExtFP[{}].csv'\n",
    "PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA_X = SPLITTED_DATA_PATH / '{}/cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv[{}]'\n",
    "\n",
    "RESULTS_KLEKOTA_ROTH_X = RESULTS_DATA_PATH / '{}/KlekFP[{}].csv'\n",
    "RESULTS_MACCS_X = RESULTS_DATA_PATH / '{}/MACCSFP[{}].csv'\n",
    "RESULTS_EXT_X = RESULTS_DATA_PATH / '{}/ExtFP[{}].csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS_DATA_X = RESULTS_DATA_PATH / '{}/KlekFP-MACCSFP[{}].csv'\n",
    "RESULTS_KLEKOTA_ROTH__EXT_DATA_X = RESULTS_DATA_PATH / '{}/KlekFP-ExtFP[{}].csv'\n",
    "RESULTS_MACCS__EXT_DATA_X = RESULTS_DATA_PATH / '{}/MACCSFP-ExtFP[{}].csv'\n",
    "RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA_X = RESULTS_DATA_PATH / '{}/KlekFP-MACCSFP-ExtFP[{}].csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0b64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"Running GridSearchCV for {key} with params {self.params[key]} with number of features {len(X.columns)}\")\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4356ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparametersTuner():\n",
    "    \n",
    "    def apply(self, input_filepath, output_filepath):\n",
    "        df = pd.read_csv(input_filepath)\n",
    "    \n",
    "        X = df.drop(['IC50','toxic'], axis=1)\n",
    "        y = df['toxic']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "        \n",
    "        print(f'Running Hyperparameters Tunning for {input_filepath}')\n",
    "        helper = EstimatorSelectionHelper(self.__prepare_models(), self.__prepare_parameters())\n",
    "        helper.fit(X_train, y_train, scoring='f1', n_jobs=4, verbose=2)\n",
    "        \n",
    "        score_summary = helper.score_summary()\n",
    "        \n",
    "        score_summary.to_csv(output_filepath, index = False)\n",
    "        \n",
    "        return score_summary\n",
    "    \n",
    "    @staticmethod\n",
    "    def __prepare_models():\n",
    "        return {\n",
    "            'LogisticRegression': LogisticRegression(), \n",
    "            'RidgeClassifier': RidgeClassifier(), \n",
    "            'SGDClassifier': SGDClassifier(), \n",
    "            'SVC': SVC(),\n",
    "            'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "            'RandomForestClassifier': RandomForestClassifier(),\n",
    "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def __prepare_parameters():\n",
    "        return {\n",
    "            'LogisticRegression': {\n",
    "                'C': [0.01, 0.1, 1, 10],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'max_iter': list(range(100,500,100)),\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "            },\n",
    "            'RidgeClassifier': {\n",
    "                'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'SGDClassifier': {\n",
    "                'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                'max_iter': list(range(100,500,100)),\n",
    "                'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "            },\n",
    "            'SVC': {\n",
    "                'C': [0.01, 0.1, 1, 10],\n",
    "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "            },\n",
    "            'ExtraTreesClassifier': {\n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "            },\n",
    "            'RandomForestClassifier': { \n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "            },\n",
    "            'AdaBoostClassifier':  { \n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "            },\n",
    "            'GradientBoostingClassifier': { \n",
    "                'n_estimators': list(range(10, 250, 50)),\n",
    "                'learning_rate': [0.4, 0.6, 0.8, 1.0] \n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae5aea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticRegression with params {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'max_iter': [100, 200, 300, 400], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.65073139        nan 0.65287648 0.74925226\n",
      " 0.74899282 0.74940862 0.74878031 0.74952277        nan        nan\n",
      " 0.65080714        nan 0.65287648 0.74925226 0.74925226 0.74940862\n",
      " 0.7493724  0.74944104        nan        nan 0.65080714        nan\n",
      " 0.65287648 0.74925226 0.74925226 0.74940862 0.74952107 0.74887029\n",
      "        nan        nan 0.65080714        nan 0.65287648 0.74925226\n",
      " 0.74925226 0.74940862 0.74952107 0.7490523         nan        nan\n",
      " 0.74280696        nan 0.74189752 0.75787509 0.75634988 0.75647366\n",
      " 0.75658653 0.75605301        nan        nan 0.74280696        nan\n",
      " 0.74112084 0.75787509 0.75707575 0.75647366 0.75673306 0.75658653\n",
      "        nan        nan 0.74304505        nan 0.74209331 0.75787509\n",
      " 0.75768125 0.75647366 0.75711657 0.75658653        nan        nan\n",
      " 0.74257221        nan 0.74176542 0.75787509 0.75811066 0.75647366\n",
      " 0.75764714 0.75673306        nan        nan 0.7536012         nan\n",
      " 0.75244487 0.7529134  0.75131132 0.75318183 0.75386522 0.75494856\n",
      "        nan        nan 0.75404355        nan 0.75269095 0.7529134\n",
      " 0.75325837 0.75318183 0.75347261 0.75354234        nan        nan\n",
      " 0.75365974        nan 0.75146119 0.7529134  0.75246723 0.75318183\n",
      " 0.75334623 0.75480894        nan        nan 0.7533349         nan\n",
      " 0.75080006 0.7529134  0.753276   0.75318183 0.75350257 0.75359434\n",
      "        nan        nan 0.73573119        nan 0.75331349 0.7444317\n",
      " 0.74964627 0.74484234 0.75377632 0.75371863        nan        nan\n",
      " 0.73581867        nan 0.75333885 0.7444317  0.74467061 0.74484234\n",
      " 0.75162074 0.75274593        nan        nan 0.73581867        nan\n",
      " 0.75425788 0.7444317  0.74562771 0.74484234 0.75224865 0.75311286\n",
      "        nan        nan 0.73586274        nan 0.75124309 0.7444317\n",
      " 0.74537754 0.74484234 0.74980319 0.75161845]\n",
      "  warnings.warn(\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.66257619        nan 0.6628457  0.81450562\n",
      " 0.81496085 0.81530685 0.81495951 0.81560651        nan        nan\n",
      " 0.6627311         nan 0.66307669 0.81450562 0.81450562 0.81530685\n",
      " 0.81466654 0.81524304        nan        nan 0.66265295        nan\n",
      " 0.66315481 0.81450562 0.81450562 0.81530685 0.8145973  0.81462835\n",
      "        nan        nan 0.66269139        nan 0.66315481 0.81450562\n",
      " 0.81450562 0.81530685 0.8145973  0.8145982         nan        nan\n",
      " 0.80006209        nan 0.80036906 0.8740567  0.87229915 0.87380072\n",
      " 0.87348885 0.87187464        nan        nan 0.80001427        nan\n",
      " 0.80050908 0.8740567  0.87359809 0.87380072 0.87401321 0.87348885\n",
      "        nan        nan 0.80003384        nan 0.800365   0.8740567\n",
      " 0.87387019 0.87380072 0.87397492 0.87384354        nan        nan\n",
      " 0.80001427        nan 0.80041371 0.8740567  0.87410931 0.87380072\n",
      " 0.87390864 0.87406506        nan        nan 0.90374029        nan\n",
      " 0.87603938 0.92413965 0.9009295  0.92406629 0.90352928 0.89020781\n",
      "        nan        nan 0.90393438        nan 0.88454678 0.92413965\n",
      " 0.92020035 0.92406629 0.91416095 0.90322853        nan        nan\n",
      " 0.9038691         nan 0.88878613 0.92413965 0.92262818 0.92406629\n",
      " 0.91891288 0.90945846        nan        nan 0.90392249        nan\n",
      " 0.89213771 0.92413965 0.92411175 0.92406629 0.921086   0.91428888\n",
      "        nan        nan 0.98454555        nan 0.89052222 0.96963959\n",
      " 0.89874326 0.96957865 0.9080302  0.89158984        nan        nan\n",
      " 0.98454555        nan 0.90574786 0.96963959 0.93599714 0.96957865\n",
      " 0.92294626 0.90781568        nan        nan 0.98448548        nan\n",
      " 0.91481582 0.96963959 0.95471052 0.96957865 0.9329488  0.91628765\n",
      "        nan        nan 0.98454555        nan 0.92080307 0.96963959\n",
      " 0.96410124 0.96957865 0.93921626 0.92283817]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RidgeClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Running GridSearchCV for SGDClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'penalty': ['l1', 'l2', 'elasticnet'], 'max_iter': [100, 200, 300, 400], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']}\n",
      "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n",
      "Running GridSearchCV for SVC with params {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Running GridSearchCV for ExtraTreesClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']}\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running GridSearchCV for RandomForestClassifier with params {'n_estimators': [10, 60, 110, 160, 210]}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for AdaBoostClassifier with params {'n_estimators': [10, 60, 110, 160, 210]}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'learning_rate': [0.4, 0.6, 0.8, 1.0]}\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "LogisticRegression\n",
      "RidgeClassifier\n",
      "SGDClassifier\n",
      "SVC\n",
      "ExtraTreesClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n"
     ]
    }
   ],
   "source": [
    "data_to_process = [\n",
    "    (PREPROCESSED_KLEKOTA_ROTH_DATA, RESULTS_KLEKOTA_ROTH), \n",
    "    (PREPROCESSED_MACCS_DATA, RESULTS_MACCS), \n",
    "    (PREPROCESSED_EXT_DATA, RESULTS_EXT),\n",
    "    \n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA, RESULTS_KLEKOTA_ROTH__MACCS_DATA),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__EXT_DATA, RESULTS_KLEKOTA_ROTH__EXT_DATA),\n",
    "    (PREPROCESSED_MACCS__EXT_DATA, RESULTS_MACCS__EXT_DATA),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA, RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA)\n",
    "]\n",
    "\n",
    "hyperparameters_tuner = HyperparametersTuner()\n",
    "results = []\n",
    "\n",
    "for data in data_to_process:\n",
    "    result = hyperparameters_tuner.apply(data[0], data[1])\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae2e7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameters Tunning for C:\\Users\\SG0306249\\PycharmProjects\\cardiotoxicity_prediction\\data\\preprocessed\\splitted\\2000\\cardiotoxicity_hERG_KlekFP-MACCSFP[2000].csv\n",
      "Running GridSearchCV for LogisticRegression with params {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'max_iter': [100, 200, 300, 400], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} with number of features 2000\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.48588979        nan 0.48596103 0.69067866\n",
      " 0.69059572 0.69084248 0.69059572 0.69068058        nan        nan\n",
      " 0.48588979        nan 0.48596103 0.69067866 0.69059572 0.69084248\n",
      " 0.69059572 0.69068058        nan        nan 0.48588979        nan\n",
      " 0.48596103 0.69067866 0.69059572 0.69084248 0.69059572 0.69068058\n",
      "        nan        nan 0.48588979        nan 0.48596103 0.69067866\n",
      " 0.69059572 0.69084248 0.69059572 0.69068058        nan        nan\n",
      " 0.68189834        nan 0.68018731 0.72986849 0.73093232 0.72874299\n",
      " 0.72986849 0.72958696        nan        nan 0.68181628        nan\n",
      " 0.68018731 0.72986849 0.72986849 0.72874299 0.72986849 0.72941822\n",
      "        nan        nan 0.68197965        nan 0.68018731 0.72986849\n",
      " 0.72986849 0.72874299 0.72986849 0.72986849        nan        nan\n",
      " 0.68197965        nan 0.68018731 0.72986849 0.72986849 0.72874299\n",
      " 0.72986849 0.72986849        nan        nan 0.7400974         nan\n",
      " 0.73694238 0.74212604 0.74150469 0.74216288 0.74197455 0.74182498\n",
      "        nan        nan 0.74018643        nan 0.73841553 0.74212604\n",
      " 0.74146998 0.74216288 0.74173379 0.74221429        nan        nan\n",
      " 0.74004054        nan 0.73773126 0.74212604 0.74110479 0.74216288\n",
      " 0.7419742  0.74212613        nan        nan 0.74024318        nan\n",
      " 0.73864806 0.74212604 0.74221925 0.74216288 0.7419742  0.74173399\n",
      "        nan        nan 0.73332159        nan 0.73611607 0.73814515\n",
      " 0.72777312 0.73838467 0.73585888 0.73607931        nan        nan\n",
      " 0.73278566        nan 0.73585061 0.73814515 0.73488898 0.73838467\n",
      " 0.7358091  0.73540578        nan        nan 0.73332159        nan\n",
      " 0.73605284 0.73814515 0.73825992 0.73838467 0.73652995 0.73567034\n",
      "        nan        nan 0.73310507        nan 0.73520628 0.73814515\n",
      " 0.73796812 0.73838467 0.73727185 0.73559415]\n",
      "  warnings.warn(\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.48835237        nan 0.48835237 0.71492252\n",
      " 0.71496527 0.71722837 0.71492252 0.71487909        nan        nan\n",
      " 0.48835237        nan 0.48835237 0.71492252 0.71496527 0.71722837\n",
      " 0.71492252 0.71487909        nan        nan 0.48835237        nan\n",
      " 0.48835237 0.71492252 0.71496527 0.71722837 0.71492252 0.71487909\n",
      "        nan        nan 0.48835237        nan 0.48835237 0.71492252\n",
      " 0.71496527 0.71722837 0.71492252 0.71487909        nan        nan\n",
      " 0.70753157        nan 0.70491623 0.78044775 0.77968257 0.78028711\n",
      " 0.78044775 0.78030374        nan        nan 0.70748779        nan\n",
      " 0.70483689 0.78044775 0.78052006 0.78028711 0.78044775 0.78042165\n",
      "        nan        nan 0.70753157        nan 0.70483689 0.78044775\n",
      " 0.78052006 0.78028711 0.78044775 0.78044775        nan        nan\n",
      " 0.70748937        nan 0.70483689 0.78044775 0.78052006 0.78028711\n",
      " 0.78044775 0.78044775        nan        nan 0.81442129        nan\n",
      " 0.8092967  0.8277559  0.82654622 0.82823245 0.82786432 0.82447484\n",
      "        nan        nan 0.8143995         nan 0.81055432 0.8277559\n",
      " 0.82833943 0.82823245 0.82802211 0.82788452        nan        nan\n",
      " 0.81451735        nan 0.81241142 0.8277559  0.82847538 0.82823245\n",
      " 0.82790385 0.82827878        nan        nan 0.81437329        nan\n",
      " 0.81270212 0.8277559  0.8277345  0.82823245 0.82785437 0.82802211\n",
      "        nan        nan 0.8649404         nan 0.83559694 0.85831266\n",
      " 0.83872673 0.85856582 0.84637049 0.83641733        nan        nan\n",
      " 0.86495747        nan 0.84539879 0.85831266 0.85291857 0.85856582\n",
      " 0.85234453 0.84601234        nan        nan 0.86495747        nan\n",
      " 0.84956257 0.85831266 0.85766475 0.85856582 0.85531107 0.85049607\n",
      "        nan        nan 0.86490597        nan 0.85198302 0.85831266\n",
      " 0.85787293 0.85856582 0.85662011 0.85203993]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RidgeClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Running GridSearchCV for SGDClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'penalty': ['l1', 'l2', 'elasticnet'], 'max_iter': [100, 200, 300, 400], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']} with number of features 2000\n",
      "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n",
      "Running GridSearchCV for SVC with params {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} with number of features 2000\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Running GridSearchCV for ExtraTreesClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running GridSearchCV for RandomForestClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for AdaBoostClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'learning_rate': [0.4, 0.6, 0.8, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running Hyperparameters Tunning for C:\\Users\\SG0306249\\PycharmProjects\\cardiotoxicity_prediction\\data\\preprocessed\\splitted\\2000\\cardiotoxicity_hERG_KlekFP-ExtFP[2000].csv\n",
      "Running GridSearchCV for LogisticRegression with params {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'max_iter': [100, 200, 300, 400], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} with number of features 2000\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53314087        nan 0.54491542 0.70194256\n",
      " 0.70185711 0.7028758  0.70178708 0.70149743        nan        nan\n",
      " 0.53314087        nan 0.54491542 0.70194256 0.70194256 0.7028758\n",
      " 0.70178708 0.70137153        nan        nan 0.53314087        nan\n",
      " 0.54491542 0.70194256 0.70194256 0.7028758  0.70178708 0.70155256\n",
      "        nan        nan 0.53314087        nan 0.54491542 0.70194256\n",
      " 0.70194256 0.7028758  0.70178708 0.70178708        nan        nan\n",
      " 0.69978221        nan 0.70037012 0.7197768  0.71961657 0.71909587\n",
      " 0.71945968 0.71943806        nan        nan 0.69986457        nan\n",
      " 0.70102575 0.7197768  0.72028773 0.71909587 0.71958349 0.71945968\n",
      "        nan        nan 0.69978221        nan 0.70102494 0.7197768\n",
      " 0.71953905 0.71909587 0.71995061 0.71951145        nan        nan\n",
      " 0.69978221        nan 0.70102494 0.7197768  0.7197768  0.71909587\n",
      " 0.7196248  0.71934359        nan        nan 0.72295369        nan\n",
      " 0.72251015 0.72661828 0.72352337 0.72661564 0.72487656 0.72496281\n",
      "        nan        nan 0.72295369        nan 0.72442815 0.72661828\n",
      " 0.72696693 0.72661564 0.72572169 0.72524452        nan        nan\n",
      " 0.72310677        nan 0.72404806 0.72661828 0.72723082 0.72661564\n",
      " 0.72659327 0.72539284        nan        nan 0.72295369        nan\n",
      " 0.72469745 0.72661828 0.7261997  0.72661564 0.72652954 0.72563599\n",
      "        nan        nan 0.72140327        nan 0.72575101 0.72252365\n",
      " 0.7215641  0.7224354  0.72595363 0.72575346        nan        nan\n",
      " 0.72140327        nan 0.72613503 0.72252365 0.72287948 0.7224354\n",
      " 0.72514356 0.72602461        nan        nan 0.7210826         nan\n",
      " 0.72672955 0.72252365 0.72011168 0.7224354  0.72380255 0.72643164\n",
      "        nan        nan 0.721339          nan 0.72480505 0.72252365\n",
      " 0.71818903 0.7224354  0.72274148 0.72568888]\n",
      "  warnings.warn(\n",
      "C:\\Users\\SG0306249\\Miniconda3\\envs\\cardiotoxicity_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.53650138        nan 0.54786373 0.75989831\n",
      " 0.75962716 0.76000935 0.76011326 0.75964827        nan        nan\n",
      " 0.53650138        nan 0.54786373 0.75989831 0.76007433 0.76000935\n",
      " 0.75982458 0.76006624        nan        nan 0.53650138        nan\n",
      " 0.54786373 0.75989831 0.76007433 0.76000935 0.75982458 0.75999608\n",
      "        nan        nan 0.53650138        nan 0.54786373 0.75989831\n",
      " 0.76007433 0.76000935 0.75982458 0.75999644        nan        nan\n",
      " 0.74802006        nan 0.74823575 0.80460802 0.80463455 0.80578716\n",
      " 0.80543965 0.80569934        nan        nan 0.74813689        nan\n",
      " 0.74764877 0.80460802 0.80478062 0.80578716 0.80507788 0.80541527\n",
      "        nan        nan 0.74791713        nan 0.74748544 0.80460802\n",
      " 0.80472515 0.80578716 0.80477167 0.80532061        nan        nan\n",
      " 0.74796156        nan 0.74748544 0.80460802 0.80467806 0.80578716\n",
      " 0.80467771 0.8049851         nan        nan 0.83065715        nan\n",
      " 0.81880523 0.8442552  0.82986847 0.84473784 0.83862502 0.83101112\n",
      "        nan        nan 0.8307267         nan 0.82521616 0.8442552\n",
      " 0.84379784 0.84473784 0.84283488 0.83849408        nan        nan\n",
      " 0.83065715        nan 0.82601564 0.8442552  0.8448405  0.84473784\n",
      " 0.8440568  0.84169577        nan        nan 0.8307267         nan\n",
      " 0.82751462 0.8442552  0.84458157 0.84473784 0.84448158 0.84278449\n",
      "        nan        nan 0.87924722        nan 0.83185472 0.87265191\n",
      " 0.83222015 0.87257977 0.84526654 0.83350935        nan        nan\n",
      " 0.87926244        nan 0.84315198 0.87265191 0.85356136 0.87257977\n",
      " 0.85409755 0.8447915         nan        nan 0.8793144         nan\n",
      " 0.84959486 0.87265191 0.86254037 0.87257977 0.85948118 0.85137231\n",
      "        nan        nan 0.87926244        nan 0.85369291 0.87265191\n",
      " 0.86865283 0.87257977 0.86239188 0.85426936]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RidgeClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Running GridSearchCV for SGDClassifier with params {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'penalty': ['l1', 'l2', 'elasticnet'], 'max_iter': [100, 200, 300, 400], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']} with number of features 2000\n",
      "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n",
      "Running GridSearchCV for SVC with params {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} with number of features 2000\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Running GridSearchCV for ExtraTreesClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Running GridSearchCV for RandomForestClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for AdaBoostClassifier with params {'n_estimators': [10, 60, 110, 160, 210]} with number of features 2000\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier with params {'n_estimators': [10, 60, 110, 160, 210], 'learning_rate': [0.4, 0.6, 0.8, 1.0]} with number of features 2000\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "data_to_process = [\n",
    "    (PREPROCESSED_KLEKOTA_ROTH_DATA_X, RESULTS_KLEKOTA_ROTH_X), \n",
    "    (PREPROCESSED_MACCS_DATA_X, RESULTS_MACCS_X), \n",
    "    (PREPROCESSED_EXT_DATA_X, RESULTS_EXT_X),\n",
    "    \n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA_X, RESULTS_KLEKOTA_ROTH__MACCS_DATA_X),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__EXT_DATA_X, RESULTS_KLEKOTA_ROTH__EXT_DATA_X),\n",
    "    (PREPROCESSED_MACCS__EXT_DATA_X, RESULTS_MACCS__EXT_DATA_X),\n",
    "    (PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA_X, RESULTS_KLEKOTA_ROTH__MACCS__EXT_DATA_X)\n",
    "]\n",
    "\n",
    "hyperparameters_tuner = HyperparametersTuner()\n",
    "results = []\n",
    "\n",
    "for x in range(500, 2500, 500):\n",
    "    for data in data_to_process:\n",
    "        input_path = Path(str(data[0]).format(x, x))\n",
    "        output_path = Path(str(data[1]).format(x, x))\n",
    "        try:\n",
    "            result = hyperparameters_tuner.apply(input_path, output_path)\n",
    "            results.append(result)\n",
    "        except:\n",
    "            print(f'Ignoring {input_path} because the file does not exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3122d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSED_KLEKOTA_ROTH_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP.csv'\n",
    "# PREPROCESSED_MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP.csv'\n",
    "# PREPROCESSED_EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_ExtFP.csv'\n",
    "# PREPROCESSED_KLEKOTA_ROTH__MACCS_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP.csv'\n",
    "# PREPROCESSED_KLEKOTA_ROTH__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-ExtFP.csv'\n",
    "# PREPROCESSED_MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_MACCSFP-ExtFP.csv'\n",
    "# PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA = PREPROCESSED_DATA_PATH / 'cardiotoxicity_hERG_KlekFP-MACCSFP-ExtFP.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(PREPROCESSED_KLEKOTA_ROTH__MACCS__EXT_DATA)\n",
    "\n",
    "X = df.drop(['IC50','toxic'], axis=1)\n",
    "y = df['toxic']\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "        \n",
    "lol = len(X_train.columns)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(lol,)),\n",
    "#     keras.layers.Dense(16, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "#     keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "# ])\n",
    "\n",
    "import keras.layers as layers\n",
    "\n",
    "# model = keras.Sequential([\n",
    "\n",
    "#     # First Convolutional Block\n",
    "#     layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\", padding='same', input_shape=(X_train,)),\n",
    "#     layers.MaxPool1D(),\n",
    "\n",
    "#     # Second Convolutional Block\n",
    "#     layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "#     layers.MaxPool1D(),\n",
    "\n",
    "#     # Third Convolutional Block\n",
    "#     layers.Conv1D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "#     layers.MaxPool1D(),\n",
    "\n",
    "#     # Classifier Head\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(units=6, activation=\"relu\"),\n",
    "#     layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "# ])\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Dense(128, input_shape=(len(X_train.columns),), kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "#     keras.layers.Dense(256, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "#     keras.layers.Dense(256, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "#     keras.layers.Dense(512, kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "#     keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "# ])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape=(lol,), kernel_regularizer=keras.regularizers.l1(0.005), activation='relu'),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7632cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "681/681 [==============================] - 3s 4ms/step - loss: 3.7843 - accuracy: 0.6665 - val_loss: 1.7911 - val_accuracy: 0.6945\n",
      "Epoch 2/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.4622 - accuracy: 0.6989 - val_loss: 1.3193 - val_accuracy: 0.6827\n",
      "Epoch 3/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.2394 - accuracy: 0.7104 - val_loss: 1.1462 - val_accuracy: 0.7244\n",
      "Epoch 4/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.1356 - accuracy: 0.7247 - val_loss: 1.1246 - val_accuracy: 0.7168\n",
      "Epoch 5/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0975 - accuracy: 0.7297 - val_loss: 1.1307 - val_accuracy: 0.7297\n",
      "Epoch 6/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.1166 - accuracy: 0.7292 - val_loss: 1.0863 - val_accuracy: 0.7256\n",
      "Epoch 7/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0654 - accuracy: 0.7355 - val_loss: 1.0738 - val_accuracy: 0.7291\n",
      "Epoch 8/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0428 - accuracy: 0.7346 - val_loss: 1.0400 - val_accuracy: 0.7380\n",
      "Epoch 9/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0440 - accuracy: 0.7339 - val_loss: 1.0564 - val_accuracy: 0.7145\n",
      "Epoch 10/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0065 - accuracy: 0.7339 - val_loss: 1.0213 - val_accuracy: 0.7156\n",
      "Epoch 11/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0218 - accuracy: 0.7439 - val_loss: 1.0690 - val_accuracy: 0.7338\n",
      "Epoch 12/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0446 - accuracy: 0.7351 - val_loss: 1.0702 - val_accuracy: 0.7086\n",
      "Epoch 13/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0159 - accuracy: 0.7482 - val_loss: 1.1092 - val_accuracy: 0.7015\n",
      "Epoch 14/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0216 - accuracy: 0.7410 - val_loss: 1.1638 - val_accuracy: 0.7080\n",
      "Epoch 15/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0251 - accuracy: 0.7408 - val_loss: 1.0193 - val_accuracy: 0.7197\n",
      "Epoch 16/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0049 - accuracy: 0.7476 - val_loss: 1.0918 - val_accuracy: 0.7227\n",
      "Epoch 17/300\n",
      "681/681 [==============================] - 2s 3ms/step - loss: 1.0188 - accuracy: 0.7485 - val_loss: 1.0582 - val_accuracy: 0.7233\n",
      "Epoch 18/300\n",
      "681/681 [==============================] - 1s 2ms/step - loss: 1.0209 - accuracy: 0.7546 - val_loss: 1.0594 - val_accuracy: 0.7221\n",
      "Epoch 19/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9952 - accuracy: 0.7485 - val_loss: 1.0206 - val_accuracy: 0.7356\n",
      "Epoch 20/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9959 - accuracy: 0.7474 - val_loss: 1.0415 - val_accuracy: 0.7250\n",
      "Epoch 21/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 1.0147 - accuracy: 0.7532 - val_loss: 1.0127 - val_accuracy: 0.7327\n",
      "Epoch 22/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9876 - accuracy: 0.7527 - val_loss: 1.0020 - val_accuracy: 0.7297\n",
      "Epoch 23/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9982 - accuracy: 0.7524 - val_loss: 1.0144 - val_accuracy: 0.7309\n",
      "Epoch 24/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9914 - accuracy: 0.7507 - val_loss: 1.0271 - val_accuracy: 0.7262\n",
      "Epoch 25/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9870 - accuracy: 0.7507 - val_loss: 1.0937 - val_accuracy: 0.7297\n",
      "Epoch 26/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9759 - accuracy: 0.7633 - val_loss: 1.0519 - val_accuracy: 0.7168\n",
      "Epoch 27/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9959 - accuracy: 0.7543 - val_loss: 1.0156 - val_accuracy: 0.7280\n",
      "Epoch 28/300\n",
      "681/681 [==============================] - 2s 2ms/step - loss: 0.9822 - accuracy: 0.7590 - val_loss: 1.0210 - val_accuracy: 0.7239\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 1.0573 - accuracy: 0.7198\n",
      "1.0573046207427979 0.7197931408882141\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                   mode='max',\n",
    "                                   patience=20,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=300, \n",
    "          batch_size=10,\n",
    "          callbacks=[es],\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(test_loss, test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
